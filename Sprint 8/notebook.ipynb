{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Review**\n","\n","Hi, my name is Dmitry and I will be reviewing your project.\n","  \n","You can find my comments in colored markdown cells:\n","  \n","<div class=\"alert alert-success\">\n","  If everything is done successfully.\n","</div>\n","  \n","<div class=\"alert alert-warning\">\n","  If I have some (optional) suggestions, or questions to think about, or general comments.\n","</div>\n","  \n","<div class=\"alert alert-danger\">\n","  If a section requires some corrections. Work can't be accepted with red comments.\n","</div>\n","  \n","Please don't remove my comments, as it will make further review iterations much harder for me.\n","  \n","Feel free to reply to my comments or ask questions using the following template:\n","  \n","<div class=\"alert alert-info\">\n","  For your comments and questions.\n","</div>\n","  \n","First of all, thank you for turning in the project! You did a great job overall, but there are a couple of problems that need to be fixed before the project is accepted. Let me know if you have questions!"]},{"cell_type":"markdown","metadata":{},"source":["# Beta Bank Customer Retention"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","This project focuses on predicting the customer churn using machine learning techniques. Customer churn refers to when a customer stops doing business with a company. Predicting churn is important for Beta Bank as it can help them identify customers who are likely to churn and take proactive steps to retain them.\n","\n","The dataset used contains information about the bank's customers and whether they exited (churned) or not. The data includes customer information such as credit score, gender, age, geography, etc.\n","\n","The project involves the following steps:\n","- Data is loaded, explored, and preprocessed. This includes handling missing values, converting data types, and dropping unnecessary columns.\n","- The target variable is imbalanced with more customers continuing their business compared to those leaving. Techniques such as upsampling the minority class and downsampling the majority class will be used to address this imbalance.\n","- A Logistic Regression model will be trained on the preprocessed data. The model's performance is evaluated using F1 score and AUC-ROC metrics.\n","- The model is then improved using upsampling and downsampling. The results will be compared before the model is improved vs after the model is improved.\n","\n","The goal of this project is to build a model that can accurately predict customer churn. The insights gained from this project could potentially be used to improve Beta Bank's customer retention strategies."]},{"cell_type":"markdown","metadata":{},"source":["## Prepare the data"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":false},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","import numpy as np\n","import warnings\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score, roc_auc_score\n","from sklearn.metrics import accuracy_score\n","\n","from sklearn.utils import resample\n","from sklearn.utils import shuffle\n","\n","from sklearn.exceptions import FitFailedWarning\n","warnings.filterwarnings(action='ignore', category=UserWarning)\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 14 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   RowNumber        10000 non-null  int64  \n"," 1   CustomerId       10000 non-null  int64  \n"," 2   Surname          10000 non-null  object \n"," 3   CreditScore      10000 non-null  int64  \n"," 4   Geography        10000 non-null  object \n"," 5   Gender           10000 non-null  object \n"," 6   Age              10000 non-null  int64  \n"," 7   Tenure           9091 non-null   float64\n"," 8   Balance          10000 non-null  float64\n"," 9   NumOfProducts    10000 non-null  int64  \n"," 10  HasCrCard        10000 non-null  int64  \n"," 11  IsActiveMember   10000 non-null  int64  \n"," 12  EstimatedSalary  10000 non-null  float64\n"," 13  Exited           10000 non-null  int64  \n","dtypes: float64(3), int64(8), object(3)\n","memory usage: 1.1+ MB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9731</th>\n","      <td>9732</td>\n","      <td>15627859</td>\n","      <td>Nebeolisa</td>\n","      <td>607</td>\n","      <td>Germany</td>\n","      <td>Male</td>\n","      <td>29</td>\n","      <td>7.0</td>\n","      <td>102609.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>163257.44</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1470</th>\n","      <td>1471</td>\n","      <td>15762332</td>\n","      <td>Ulyanova</td>\n","      <td>568</td>\n","      <td>Germany</td>\n","      <td>Female</td>\n","      <td>31</td>\n","      <td>1.0</td>\n","      <td>61592.14</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>61796.64</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4059</th>\n","      <td>4060</td>\n","      <td>15691952</td>\n","      <td>Fanucci</td>\n","      <td>676</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>37</td>\n","      <td>10.0</td>\n","      <td>106242.67</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>166678.28</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1311</th>\n","      <td>1312</td>\n","      <td>15750497</td>\n","      <td>Longo</td>\n","      <td>850</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>37</td>\n","      <td>7.0</td>\n","      <td>153147.75</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>152235.30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1251</th>\n","      <td>1252</td>\n","      <td>15814930</td>\n","      <td>McGregor</td>\n","      <td>588</td>\n","      <td>Germany</td>\n","      <td>Female</td>\n","      <td>40</td>\n","      <td>10.0</td>\n","      <td>125534.51</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>121504.18</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3269</th>\n","      <td>3270</td>\n","      <td>15774744</td>\n","      <td>Lord</td>\n","      <td>664</td>\n","      <td>Germany</td>\n","      <td>Male</td>\n","      <td>33</td>\n","      <td>NaN</td>\n","      <td>97286.16</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>143433.33</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>479</th>\n","      <td>480</td>\n","      <td>15797736</td>\n","      <td>Smith</td>\n","      <td>658</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>29</td>\n","      <td>4.0</td>\n","      <td>80262.60</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>20612.82</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5850</th>\n","      <td>5851</td>\n","      <td>15762091</td>\n","      <td>Simpson</td>\n","      <td>631</td>\n","      <td>Germany</td>\n","      <td>Female</td>\n","      <td>22</td>\n","      <td>6.0</td>\n","      <td>139129.92</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>63747.51</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3064</th>\n","      <td>3065</td>\n","      <td>15762228</td>\n","      <td>Barnes</td>\n","      <td>506</td>\n","      <td>Spain</td>\n","      <td>Male</td>\n","      <td>35</td>\n","      <td>6.0</td>\n","      <td>110046.93</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>26318.73</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1443</th>\n","      <td>1444</td>\n","      <td>15598751</td>\n","      <td>Ingram</td>\n","      <td>556</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>NaN</td>\n","      <td>0.00</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>125154.57</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n","9731       9732    15627859  Nebeolisa          607   Germany    Male   29   \n","1470       1471    15762332   Ulyanova          568   Germany  Female   31   \n","4059       4060    15691952    Fanucci          676    France    Male   37   \n","1311       1312    15750497      Longo          850    France  Female   37   \n","1251       1252    15814930   McGregor          588   Germany  Female   40   \n","3269       3270    15774744       Lord          664   Germany    Male   33   \n","479         480    15797736      Smith          658    France    Male   29   \n","5850       5851    15762091    Simpson          631   Germany  Female   22   \n","3064       3065    15762228     Barnes          506     Spain    Male   35   \n","1443       1444    15598751     Ingram          556    France  Female   43   \n","\n","      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","9731     7.0  102609.00              1          1               0   \n","1470     1.0   61592.14              2          1               1   \n","4059    10.0  106242.67              1          1               1   \n","1311     7.0  153147.75              1          1               1   \n","1251    10.0  125534.51              1          1               0   \n","3269     NaN   97286.16              2          1               0   \n","479      4.0   80262.60              1          1               1   \n","5850     6.0  139129.92              1          1               1   \n","3064     6.0  110046.93              2          1               0   \n","1443     NaN       0.00              3          0               0   \n","\n","      EstimatedSalary  Exited  \n","9731        163257.44       0  \n","1470         61796.64       0  \n","4059        166678.28       0  \n","1311        152235.30       0  \n","1251        121504.18       1  \n","3269        143433.33       0  \n","479          20612.82       0  \n","5850         63747.51       0  \n","3064         26318.73       0  \n","1443        125154.57       1  "]},"metadata":{},"output_type":"display_data"}],"source":["# Read the data\n","data = pd.read_csv('https://practicum-content.s3.us-west-1.amazonaws.com/datasets/Churn.csv')\n","\n","# Examine the data\n","data.info()\n","display(data.sample(10))"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["# Check for duplicates\n","print(data.duplicated().sum())"]},{"cell_type":"markdown","metadata":{},"source":["There are no duplicate rows, so we can move on."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-success\">\n","<b>Reviewer's comment</b>\n","\n","The data was loaded and inspected!\n","\n","</div>"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["RowNumber            0\n","CustomerId           0\n","Surname              0\n","CreditScore          0\n","Geography            0\n","Gender               0\n","Age                  0\n","Tenure             909\n","Balance              0\n","NumOfProducts        0\n","HasCrCard            0\n","IsActiveMember       0\n","EstimatedSalary      0\n","Exited               0\n","dtype: int64\n"]}],"source":["# Check for missing values\n","print(data.isnull().sum())"]},{"cell_type":"markdown","metadata":{},"source":["There are 909 missing values for the 'Tenure' column. Some models will not be able to handle data with missing values. Therefore, we will fill in the missing values for tenure with the median value. We will also change the data type of 'Tenure' to integers if all the values are integers."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-success\">\n","<b>Reviewer's comment</b>\n","\n","Alright, that's one way to deal with missing values :)\n","\n","</div>"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 14 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   RowNumber        10000 non-null  int64  \n"," 1   CustomerId       10000 non-null  int64  \n"," 2   Surname          10000 non-null  object \n"," 3   CreditScore      10000 non-null  int64  \n"," 4   Geography        10000 non-null  object \n"," 5   Gender           10000 non-null  object \n"," 6   Age              10000 non-null  int64  \n"," 7   Tenure           10000 non-null  int32  \n"," 8   Balance          10000 non-null  float64\n"," 9   NumOfProducts    10000 non-null  int64  \n"," 10  HasCrCard        10000 non-null  int64  \n"," 11  IsActiveMember   10000 non-null  int64  \n"," 12  EstimatedSalary  10000 non-null  float64\n"," 13  Exited           10000 non-null  int64  \n","dtypes: float64(2), int32(1), int64(8), object(3)\n","memory usage: 1.0+ MB\n","None\n"]}],"source":["# Fill missing values in 'Tenure' with the median value\n","data['Tenure'].fillna(data['Tenure'].median(), inplace=True)\n","\n","# Check to see if it's save to convert 'Tenure' from float to int. If so, then convert it.\n","if np.array_equal(data['Tenure'], data['Tenure'].astype('int')):\n","    data['Tenure'] = data['Tenure'].astype('int')\n","\n","print(data.info())\n"]},{"cell_type":"markdown","metadata":{},"source":["We will now remove the columns that are not needed."]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8210</th>\n","      <td>703</td>\n","      <td>Spain</td>\n","      <td>Male</td>\n","      <td>31</td>\n","      <td>6</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>67667.19</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4969</th>\n","      <td>655</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>35</td>\n","      <td>1</td>\n","      <td>106405.03</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>82900.25</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8412</th>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>22</td>\n","      <td>9</td>\n","      <td>99339.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>68297.61</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4592</th>\n","      <td>834</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>36</td>\n","      <td>8</td>\n","      <td>142882.49</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>89983.02</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6450</th>\n","      <td>834</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>28</td>\n","      <td>6</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>74287.53</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8201</th>\n","      <td>718</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>49</td>\n","      <td>10</td>\n","      <td>82321.88</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>11144.40</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2864</th>\n","      <td>708</td>\n","      <td>Germany</td>\n","      <td>Male</td>\n","      <td>37</td>\n","      <td>8</td>\n","      <td>153366.13</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>26912.34</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3465</th>\n","      <td>692</td>\n","      <td>Germany</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>69014.49</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>164621.43</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>923</th>\n","      <td>572</td>\n","      <td>Germany</td>\n","      <td>Female</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>138657.08</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>16161.82</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7262</th>\n","      <td>641</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>40</td>\n","      <td>5</td>\n","      <td>101090.27</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>51703.09</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n","8210          703     Spain    Male   31       6       0.00              2   \n","4969          655     Spain  Female   35       1  106405.03              1   \n","8412          699    France    Male   22       9   99339.00              1   \n","4592          834    France    Male   36       8  142882.49              1   \n","6450          834    France  Female   28       6       0.00              1   \n","8201          718     Spain  Female   49      10   82321.88              1   \n","2864          708   Germany    Male   37       8  153366.13              1   \n","3465          692   Germany  Female   43       2   69014.49              2   \n","923           572   Germany  Female   19       1  138657.08              1   \n","7262          641     Spain  Female   40       5  101090.27              1   \n","\n","      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n","8210          1               1         67667.19       0  \n","4969          1               1         82900.25       0  \n","8412          1               0         68297.61       1  \n","4592          1               0         89983.02       1  \n","6450          1               0         74287.53       0  \n","8201          0               1         11144.40       0  \n","2864          1               1         26912.34       0  \n","3465          0               0        164621.43       0  \n","923           1               1         16161.82       0  \n","7262          1               1         51703.09       0  "]},"metadata":{},"output_type":"display_data"}],"source":["# Drop the columns that are not needed for the model\n","data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n","\n","display(data.sample(10))"]},{"cell_type":"markdown","metadata":{},"source":["These columns were dropped since they do not contribute to the model's prediction of customer churn. For RowNumber is an index column that does not provide meaningful information for the model. CustomerId is a unique identifier for each customer. Including this in the model could associate specific outcomes to the individual customer IDs and may not work well with unseen data. Surname is the customer's last name, which will probably not have influence towards their likelihood to churn."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-success\">\n","<b>Reviewer's comment</b>\n","\n","Make sense!\n","\n","</div>"]},{"cell_type":"code","execution_count":7,"metadata":{"scrolled":true,"trusted":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CreditScore</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","      <th>Geography_Germany</th>\n","      <th>Geography_Spain</th>\n","      <th>Gender_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2764</th>\n","      <td>660</td>\n","      <td>38</td>\n","      <td>7</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>146585.53</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1916</th>\n","      <td>543</td>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>100900.50</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>33310.72</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3892</th>\n","      <td>549</td>\n","      <td>45</td>\n","      <td>6</td>\n","      <td>124240.93</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>146372.51</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>8264</th>\n","      <td>742</td>\n","      <td>33</td>\n","      <td>5</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38550.40</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4446</th>\n","      <td>701</td>\n","      <td>37</td>\n","      <td>3</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>164268.28</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8837</th>\n","      <td>664</td>\n","      <td>46</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>177423.02</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9818</th>\n","      <td>558</td>\n","      <td>31</td>\n","      <td>7</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>198269.08</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>687</td>\n","      <td>27</td>\n","      <td>9</td>\n","      <td>152328.88</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>126494.82</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>533</th>\n","      <td>543</td>\n","      <td>35</td>\n","      <td>10</td>\n","      <td>59408.63</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>76773.53</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4565</th>\n","      <td>593</td>\n","      <td>46</td>\n","      <td>2</td>\n","      <td>76597.79</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>54453.72</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n","2764          660   38       7       0.00              2          0   \n","1916          543   48       1  100900.50              1          0   \n","3892          549   45       6  124240.93              1          1   \n","8264          742   33       5       0.00              2          0   \n","4446          701   37       3       0.00              2          1   \n","8837          664   46       2       0.00              1          1   \n","9818          558   31       7       0.00              1          1   \n","61            687   27       9  152328.88              2          0   \n","533           543   35      10   59408.63              1          1   \n","4565          593   46       2   76597.79              1          1   \n","\n","      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n","2764               1        146585.53       0              False   \n","1916               0         33310.72       1               True   \n","3892               1        146372.51       0               True   \n","8264               0         38550.40       0              False   \n","4446               1        164268.28       0              False   \n","8837               1        177423.02       1              False   \n","9818               0        198269.08       0              False   \n","61                 0        126494.82       0               True   \n","533                0         76773.53       0              False   \n","4565               1         54453.72       0              False   \n","\n","      Geography_Spain  Gender_Male  \n","2764            False         True  \n","1916            False         True  \n","3892            False         True  \n","8264            False         True  \n","4446            False        False  \n","8837            False         True  \n","9818            False         True  \n","61              False        False  \n","533              True         True  \n","4565             True        False  "]},"metadata":{},"output_type":"display_data"}],"source":["# Convert categorical data into numerical data\n","data = pd.get_dummies(data, drop_first=True)\n","\n","display(data.sample(10))"]},{"cell_type":"markdown","metadata":{},"source":["We have the new dataframe that has the categories placed into separate columns. To avoid the dummy variable trap, the drop_first argument for get_dummies doesn't include a Geography_France column. It is assumed that the geography is France if it is not Germany or Spain. Same with Gender_Male assuming the gender is Female if Gender_Male is false."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-success\">\n","<b>Reviewer's comment</b>\n","\n","Categorical features were encoded\n","\n","</div>"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":false},"outputs":[],"source":["# Split the data into features and target\n","# The 'Exited' column is the target, the rest are features\n","features = data.drop('Exited', axis=1)\n","target = data['Exited']\n","\n","# First, split the data into a training set (60% of the data) and a temp set (40%)\n","features_train, features_temp, target_train, target_temp = train_test_split(\n","    features, target, test_size=0.4, random_state=42)\n","\n","# Then, split the temp set into a validation set (50% of the temp) and a testing set (50% of the temp)\n","# This will result in a 20/20 split of the entire dataset for validation/testing\n","features_valid, features_test, target_valid, target_test = train_test_split(\n","    features_temp, target_temp, test_size=0.5, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger\">\n","<b>Reviewer's comment</b>\n","\n","Note that we need three sets here: train, validation and test. Train set to train the models, validation to compare different models and balancing tehchniques as well as tune hyperparameters, and the test set to evaluate the final model\n","\n","</div>"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Exited\n","0    7963\n","1    2037\n","Name: count, dtype: int64\n"]}],"source":["# Examine the balance of classes\n","class_counts = target.value_counts()\n","print(class_counts)\n"]},{"cell_type":"markdown","metadata":{},"source":["This code shows the number of customers who stayed with the company vs those who took their business elsewhere. It shows that there are significantly more customers who are loyal customers than those who left."]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Imbalance Ratio: 3.9091801669121256\n"]}],"source":["# Calculate the imbalance ratio\n","imbalance_ratio = class_counts[0] / class_counts[1]\n","print(f'Imbalance Ratio: {imbalance_ratio}')"]},{"cell_type":"markdown","metadata":{},"source":["This shows that there are about 4 times the loyal customers as there are who took their business elsewhere at the time the data was collected."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-success\">\n","<b>Reviewer's comment</b>\n","\n","Class distribution was examined\n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["## Train the model"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":false},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(random_state=42, solver='liblinear')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Train a Logistic Regression model without considering the imbalance\n","model = LogisticRegression(solver='liblinear', random_state=42)\n","model.fit(features_train, target_train)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":false},"outputs":[],"source":["# Make predictions on the test set\n","predictions_valid = model.predict(features_valid)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.99      0.89      1620\n","           1       0.33      0.02      0.04       380\n","\n","    accuracy                           0.81      2000\n","   macro avg       0.57      0.51      0.47      2000\n","weighted avg       0.72      0.81      0.73      2000\n","\n"]}],"source":["# Evaluate the model\n","print(classification_report(target_valid, predictions_valid))"]},{"cell_type":"markdown","metadata":{},"source":["Here's what can be seen from the results:\n","- The precision, which is the ratio of correctly predicted positive observations to the total predicted positives vs false positives, is high with for 0, but relatively low for 1. The precision is .81 for 0 and .45 for 1.\n","- Recall is the ratio of correctly predicted positive observations to all the observations in the class. For 0, the recall is .98, while for 1, the recall is .07.\n","- F1 score is the weighted average of Precision and Recall. This score takes both false positive and false negatives into account. It is a better measure than accuracy for uneven class distribution such as what we have in our data. The F1 score for 0 is .89, while the F1 score for 1 is 0.12.\n","- Support is the number of actual occurences of the class specified in the dataset. For 0, it is 1607 and 1 is 393.\n","\n","From these metrics, we can conclude that the model is performing well in predicting customers who did not exit (0), but not as well as predicting customers who exited."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger\">\n","<b>Reviewer's comment</b>\n","\n","Great, you trained a model without taking the imbalance into account first. Note that you need to use the validation set to evaluate the model here: the test set should only be used once you've selected the model and are not going to make any changes. The same goes for models below\n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["## Improve the model\n","\n","We will use upsampling and downsampling to improve our model."]},{"cell_type":"markdown","metadata":{},"source":["### Logistic Regression"]},{"cell_type":"markdown","metadata":{},"source":["#### Hyperparameter Tuning\n","Use GridSearchCV on Logistic Regression model for hyperparameter testing."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Ignore FitFailedWarning\n","warnings.filterwarnings('ignore', category=FitFailedWarning)\n","\n","# Hyperparameter tuning\n","param_grid = {\n","    'C': np.logspace(-3, 3, 7), \n","    'penalty': ['l1', 'l2'],\n","    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n","    'class_weight': [None, 'balanced'],\n","    'fit_intercept': [True, False],\n","    'max_iter': [100, 200, 300]\n","}\n","\n","gridsearch = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='f1')"]},{"cell_type":"markdown","metadata":{},"source":["#### Upsampling"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Upsampling Target Value Counts: \n","Exited\n","1    4773\n","0    4773\n","Name: count, dtype: int64\n"]},{"name":"stdout","output_type":"stream","text":["Upsampling Best Params:  {'C': 0.01, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 200, 'penalty': 'l2', 'solver': 'newton-cg'}\n","Upsampling F1 Score:  0.46696035242290745\n","Upsampling ROC-AUC Score:  0.6974496426250811\n"]}],"source":["# Upsampling\n","def upsample(features, target, repeat=None):\n","    # Separate majority and minority classes\n","    features_zeros = features[target == 0]\n","    features_ones = features[target == 1]\n","    target_zeros = target[target == 0]\n","    target_ones = target[target == 1]\n","\n","    # Upsample minority class to match the number of samples in majority class\n","    features_upsampled = pd.concat([features_zeros] + [resample(features_ones, replace=True, n_samples=len(features_zeros), random_state=42)])\n","    target_upsampled = pd.concat([target_zeros] + [resample(target_ones, replace=True, n_samples=len(target_zeros), random_state=42)])\n","    \n","    # Shuffle the dataset\n","    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=42)\n","    \n","    return features_upsampled, target_upsampled\n","\n","features_upsampled, target_upsampled = upsample(features_train, target_train)\n","print(\"Upsampling Target Value Counts: \")\n","print(target_upsampled.value_counts())\n","gridsearch.fit(features_upsampled, target_upsampled)\n","print(\"Upsampling Best Params: \", gridsearch.best_params_)\n","predictions_valid = gridsearch.predict(features_valid)\n","print(\"Upsampling F1 Score: \", f1_score(target_valid, predictions_valid))\n","print(\"Upsampling ROC-AUC Score: \", roc_auc_score(target_valid, predictions_valid))"]},{"cell_type":"markdown","metadata":{},"source":["#### Downsampling"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Downsampling Target Value Counts: \n","Exited\n","1    1227\n","0    1227\n","Name: count, dtype: int64\n","Downsampling Best Params:  {'C': 1.0, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n","Downsampling F1 Score:  0.46341463414634143\n","Downsampling ROC-AUC Score:  0.6950617283950616\n"]}],"source":["# Downsampling\n","def downsample(features, target, fraction=None):\n","    # Separate majority and minority classes\n","    features_zeros = features[target == 0]\n","    features_ones = features[target == 1]\n","    target_zeros = target[target == 0]\n","    target_ones = target[target == 1]\n","\n","    # Downsample majority class to match the number of samples in minority class\n","    features_downsampled = pd.concat([resample(features_zeros, replace=False, n_samples=len(features_ones), random_state=42)] + [features_ones])\n","    target_downsampled = pd.concat([resample(target_zeros, replace=False, n_samples=len(target_ones), random_state=42)] + [target_ones])\n","    \n","    # Shuffle the dataset\n","    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=42)\n","    \n","    return features_downsampled, target_downsampled\n","\n","\n","features_downsampled, target_downsampled = downsample(features_train, target_train)\n","print(\"Downsampling Target Value Counts: \")\n","print(target_downsampled.value_counts())\n","gridsearch.fit(features_downsampled, target_downsampled)\n","print(\"Downsampling Best Params: \", gridsearch.best_params_)\n","predictions_valid = gridsearch.predict(features_valid)\n","print(\"Downsampling F1 Score: \", f1_score(target_valid, predictions_valid))\n","print(\"Downsampling ROC-AUC Score: \", roc_auc_score(target_valid, predictions_valid))"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest"]},{"cell_type":"markdown","metadata":{},"source":["#### Hyperparameter Tuning\n","Use GridSearchCV on Random Forest model for hyperparameter testing.\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Hyperparameter tuning\n","param_grid = {\n","    'n_estimators': range(10, 201, 10), \n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False],\n","    'class_weight': [None, 'balanced']\n","}\n","\n","gridsearch = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='f1')"]},{"cell_type":"markdown","metadata":{},"source":["#### Upsampling"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[21], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features_upsampled, target_upsampled\n\u001b[0;32m     18\u001b[0m features_upsampled, target_upsampled \u001b[38;5;241m=\u001b[39m upsample(features_train, target_train)\n\u001b[1;32m---> 19\u001b[0m gridsearch\u001b[38;5;241m.\u001b[39mfit(features_upsampled, target_upsampled)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpsampling Best Params: \u001b[39m\u001b[38;5;124m\"\u001b[39m, gridsearch\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     21\u001b[0m probabilities_valid \u001b[38;5;241m=\u001b[39m gridsearch\u001b[38;5;241m.\u001b[39mpredict_proba(features_valid)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Users\\cosmi\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Upsampling\n","def upsample(features, target, repeat=None):\n","    # Separate majority and minority classes\n","    features_zeros = features[target == 0]\n","    features_ones = features[target == 1]\n","    target_zeros = target[target == 0]\n","    target_ones = target[target == 1]\n","\n","    # Upsample minority class to match the number of samples in majority class\n","    features_upsampled = pd.concat([features_zeros] + [resample(features_ones, replace=True, n_samples=len(features_zeros), random_state=42)])\n","    target_upsampled = pd.concat([target_zeros] + [resample(target_ones, replace=True, n_samples=len(target_zeros), random_state=42)])\n","    \n","    # Shuffle the dataset\n","    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=42)\n","    \n","    return features_upsampled, target_upsampled\n","\n","features_upsampled, target_upsampled = upsample(features_train, target_train)\n","gridsearch.fit(features_upsampled, target_upsampled)\n","print(\"Upsampling Best Params: \", gridsearch.best_params_)\n","probabilities_valid = gridsearch.predict_proba(features_valid)\n","predicted_valid = probabilities_valid[:, 1] > 0.4  # custom threshold\n","print(\"Upsampling F1 Score: \", f1_score(target_valid, predicted_valid))\n","print(\"Upsampling ROC-AUC Score: \", roc_auc_score(target_valid, predicted_valid))"]},{"cell_type":"markdown","metadata":{},"source":["#### Downsampling"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downsampling Target Value Counts: \n","Exited\n","1    1227\n","0    1227\n","Name: count, dtype: int64\n","Downsampling Best Params:  {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n","Downsampling F1 Score:  0.5412935323383085\n","Downsampling ROC-AUC Score:  0.7489441195581547\n"]}],"source":["# Downsampling\n","def downsample(features, target, fraction=None):\n","    # Separate majority and minority classes\n","    features_zeros = features[target == 0]\n","    features_ones = features[target == 1]\n","    target_zeros = target[target == 0]\n","    target_ones = target[target == 1]\n","\n","    # Downsample majority class to match the number of samples in minority class\n","    features_downsampled = pd.concat([resample(features_zeros, replace=False, n_samples=len(features_ones), random_state=42)] + [features_ones])\n","    target_downsampled = pd.concat([resample(target_zeros, replace=False, n_samples=len(target_ones), random_state=42)] + [target_ones])\n","    \n","    # Shuffle the dataset\n","    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=42)\n","    \n","    return features_downsampled, target_downsampled\n","\n","features_downsampled, target_downsampled = downsample(features_train, target_train)\n","gridsearch.fit(features_downsampled, target_downsampled)\n","print(\"Downsampling Best Params: \", gridsearch.best_params_)\n","probabilities_valid = gridsearch.predict_proba(features_valid)\n","predicted_valid = probabilities_valid[:, 1] > 0.4  # custom threshold\n","print(\"Downsampling F1 Score: \", f1_score(target_valid, predicted_valid))\n","print(\"Downsampling ROC-AUC Score: \", roc_auc_score(target_valid, predicted_valid))\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger\">\n","<b>Reviewer's comment</b>\n","\n","Upampling should be applied only to the train set, otherwise it won't be possible to accurately estimate how the model will generalize to new data for two reasons:\n","    \n","1. Validation/test data obtained from an upsampled full dataset will not have the same distribution as actual data (which is not balanced)\n","2. There are bound to be the same examples in train and test, which is a clear case of data leakage.\n","    \n","The goal of upsampling is just to help the model better learn about the underrepresented class, but the validation and test set need to have the original data distribution in order for evaluation to make any sense.\n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger\">\n","<b>Reviewer's comment</b>\n","\n","The same comment as for upsampling: downsampling should only be applied to the train set. While the argument about having the same examples in train and test no longer works, the first point about validation/test data needing to have the original data distribution for accurate estimation of generalization performance applies here.\n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["## Testing"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger\">\n","<b>Reviewer's comment</b>\n","\n","Please check the results after making sure that the test set is only used for final model evaluation and all prior comparisons are done using the validation set \n","\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion\n","\n","This project involved building a machine learning model to predict customer churn. The dataset was initially imbalanced with a larger number of customers who continued their business with Beta Bank compared to those who did not. The initial model which was trained without addressing the imbalance performed poorly having a low F1 score for the minority class. After addressing the class imbalance using both upsampling and downsampling, the F1 scores improved dramatically from .12 to around .63-.64. The AUC-ROC scores of the improved model was around .65-.69.\n","\n","This project demonstrated the importance of properly preprocessing the data, handling class imbalance, and choosing the right evaluation metrics when working with imbalanced datasets. It also shows the iterative process of building a model and continually improving the model based on performance."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-danger\">\n","<b>Reviewer's comment</b>\n","\n","Don't forget to change the conclusions if needed\n","\n","</div>"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":2}
