{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megaline Recommended Plan Based on User Behavior\n",
    "\n",
    "In this project, we are working with a mobile carrier named Megaline. The company offers its customers two prepaid plans, “Smart” and “Ultra”. Many of the company’s subscribers use legacy plans, and Megaline wants to encourage them to switch to these newer plans.\n",
    "\n",
    "The main objective of the project is to develop a machine learning model that can analyze the behavior of the subscribers and predict which plan is more suitable for them. The model will use data about the subscribers’ behavior, such as the number of calls they made, total call duration in minutes, number of text messages sent, and internet traffic used in MB.\n",
    "\n",
    "The model will be trained on a dataset containing behavior data about subscribers who have already switched to the new plans. The goal is to achieve a model with the highest possible accuracy, with a threshold for accuracy set at 0.75.\n",
    "\n",
    "The project involves several steps, including data preprocessing, model training, hyperparameter tuning, and model evaluation. We will also perform a sanity check on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, examine, and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "\n",
      "Statistical summary:\n",
      "              calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "Correlations:\n",
      "              calls   minutes  messages   mb_used  is_ultra\n",
      "calls     1.000000  0.982083  0.177385  0.286442  0.207122\n",
      "minutes   0.982083  1.000000  0.173110  0.280967  0.206955\n",
      "messages  0.177385  0.173110  1.000000  0.195721  0.203830\n",
      "mb_used   0.286442  0.280967  0.195721  1.000000  0.198568\n",
      "is_ultra  0.207122  0.206955  0.203830  0.198568  1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>62.0</td>\n",
       "      <td>448.76</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15522.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>47.0</td>\n",
       "      <td>378.52</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9804.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>36.0</td>\n",
       "      <td>259.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7417.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>76.0</td>\n",
       "      <td>484.49</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22454.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>76.0</td>\n",
       "      <td>535.91</td>\n",
       "      <td>65.0</td>\n",
       "      <td>11968.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "1834   62.0   448.76      62.0  15522.01         0\n",
       "2665   47.0   378.52      47.0   9804.44         0\n",
       "730    36.0   259.50       8.0   7417.14         0\n",
       "2294   76.0   484.49      11.0  22454.35         0\n",
       "46     76.0   535.91      65.0  11968.22         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data and examine it\n",
    "try:\n",
    "    behavior = pd.read_csv('./datasets/users_behavior.csv')\n",
    "except:\n",
    "    behavior = pd.read_csv('https://practicum-content.s3.us-west-1.amazonaws.com/datasets/users_behavior.csv')\n",
    "\n",
    "# Show the information of the dataframe\n",
    "behavior.info()\n",
    "\n",
    "# Show statistical summary of the data\n",
    "print('\\nStatistical summary:\\n', behavior.describe())\n",
    "\n",
    "# See if there are any correlations\n",
    "print('\\nCorrelations:\\n', behavior.corr())\n",
    "display(behavior.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert columns into appropriate data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   int32  \n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   int32  \n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(2), int32(2), int64(1)\n",
      "memory usage: 100.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Convert calls and messages from float to int\n",
    "if np.array_equal(behavior['calls'], behavior['calls'].astype('int')):\n",
    "  behavior['calls'] = behavior['calls'].astype('int')\n",
    "if np.array_equal(behavior['messages'], behavior['messages'].astype('int')):\n",
    "  behavior['messages'] = behavior['messages'].astype('int')\n",
    "\n",
    "behavior.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(behavior.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks line there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows = 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = behavior.duplicated()\n",
    "print(f\"Number of duplicate rows = {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the source data into data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the source data into a training set, a validation set, and a test set.\n",
    "\n",
    "# Split the data into a training set and a temporary set with an 60-40 split\n",
    "train, temp = train_test_split(behavior, test_size=0.25, random_state=54321)\n",
    "\n",
    "# Split the temporary set into a test set and validation set\n",
    "# This gives the data the 60-20-20 split with equal test and validation sizes\n",
    "valid, test = train_test_split(temp, test_size=0.5, random_state=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features variables\n",
    "features_train = train.drop('is_ultra', axis=1) # X_train\n",
    "features_valid = valid.drop('is_ultra', axis=1) # X_valid\n",
    "\n",
    "# Create the target variables:\n",
    "target_train = train['is_ultra'] # y_train\n",
    "target_valid = valid['is_ultra'] # y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth = 1 : 0.7313432835820896\n",
      "Max Depth = 2 : 0.7611940298507462\n",
      "Max Depth = 3 : 0.7736318407960199\n",
      "Max Depth = 4 : 0.7711442786069652\n",
      "Max Depth = 5 : 0.7786069651741293\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with different max depths\n",
    "for depth in range(1,6):\n",
    "  model = DecisionTreeClassifier(random_state=54321, max_depth=depth)\n",
    "  model.fit(features_train, target_train)\n",
    "  predictions_valid = model.predict(features_valid)\n",
    "  print(\"Max Depth =\", depth, \": \", end='')\n",
    "  print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decision tree, the higher the max depth is, the more accurate it is. At max depth of 5, the model is 77.8% accurate in its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 : 0.7860696517412935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 20 : 0.7960199004975125\n",
      "n_estimators = 30 : 0.7985074626865671\n",
      "n_estimators = 40 : 0.7935323383084577\n",
      "n_estimators = 50 : 0.7960199004975125\n",
      "n_estimators = 60 : 0.7985074626865671\n",
      "n_estimators = 70 : 0.8009950248756219\n",
      "n_estimators = 80 : 0.8009950248756219\n",
      "n_estimators = 90 : 0.8059701492537313\n",
      "n_estimators = 100 : 0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "for n in range(10, 101, 10):\n",
    "  model = RandomForestClassifier(random_state=54321, n_estimators=n)\n",
    "  model.fit(features_train, target_train)\n",
    "  predictions_valid = model.predict(features_valid)\n",
    "  print(\"n_estimators =\", n, \": \", end='')\n",
    "  print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even at 10 n_estimators, the random forest model seems to have a higher accuracy than the decision tree model. It is slower since it uses many trees for its decision, but it is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 0.7178423236514523\n",
      "Accuracy of the logistic regression model on the validation set: 0.6940298507462687\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression constructor\n",
    "model = LogisticRegression(random_state=54321, solver='liblinear')\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Calculate the accuracy score on the training set\n",
    "score_train = model.score(features_train, target_train)\n",
    "\n",
    "# Calculate the accuracy score on the validation set\n",
    "score_valid = model.score(features_valid, target_valid)\n",
    "\n",
    "# Print the accuracy of the logistic regression model on the training set\n",
    "print(\"Accuracy of the logistic regression model on the training set:\", score_train)\n",
    "\n",
    "# Print the accuracy of the logistic regression model on the validation set\n",
    "print(\"Accuracy of the logistic regression model on the validation set:\", score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistic regression model, we got 71% and 69% accuracy on the training set and validation set respectively. Although logistic regression is faster than the random forest model, it is less accurate.\n",
    "\n",
    "We will use the random forest model for our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8009950248756219\n"
     ]
    }
   ],
   "source": [
    "# We are using the Random Forest model since it is the most accurate.\n",
    "# Create the variables for the test set\n",
    "features_test = test.drop('is_ultra', axis=1)\n",
    "target_test = test['is_ultra']\n",
    "\n",
    "model = RandomForestClassifier(random_state=54321, n_estimators=70)\n",
    "model.fit(features_train, target_train)\n",
    "predictions_test = model.predict(features_test)\n",
    "print(\"Test Accuracy: \", accuracy_score(target_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the random forest model used is at 80%. This means that the predictions that the model will make will be correct 80% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the model is better than a random model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Model Accuracy: 0.5870646766169154\n"
     ]
    }
   ],
   "source": [
    "# Generate random predictions based on the class distribution of the training set\n",
    "random_predictions = np.random.choice([0, 1], size=len(target_test), p=[1 - target_train.mean(), target_train.mean()])\n",
    "\n",
    "# Calculate the accuracy of the random predictions\n",
    "random_accuracy = accuracy_score(target_test, random_predictions)\n",
    "print(f\"Random Model Accuracy: {random_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random model accuracy fluctuates from 0.53 to 0.63. Since the random forest model has a higher accuracy than the random model accuracy, there's a good chance the model is learning something from the data and not just making random guesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the model is better than a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model Accuracy: 0.681592039800995\n"
     ]
    }
   ],
   "source": [
    "# Generate simple predictions by always predicting the most common class\n",
    "simple_predictions = np.full_like(target_test, target_train.mode()[0])\n",
    "\n",
    "# Calculate the accuracy of the simple predictions\n",
    "simple_accuracy = accuracy_score(target_test, simple_predictions)\n",
    "print(f\"Simple Model Accuracy: {simple_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the accuracy of the model that always predicts the most common class. The accuracy of 0.68, which is lower than the model's accuracy. It is a good sign that the model is learning from the data rather than just predicting the most common class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[252  22]\n",
      " [ 58  70]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(target_test, model.predict(features_test))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, the model has:\n",
    "\n",
    "[[True Negatives (TN)  False Positives (FP)]\\\n",
    " [False Negatives (FN) True Positives (TP)]]\n",
    "\n",
    "- 252 True Negatives where the model predicted 0 (Smart plan) and the actual is 0.\n",
    "- 22 False Positives where the model incorrectly predicted 1 when the actual is 0.\n",
    "- 58 False negatives where the model incorrectly predicted 0 when the actual is 1.\n",
    "- 70 True Positives where the model correctly predicted 1 when the actual is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls: 0.20454833414323342\n",
      "minutes: 0.26672329580491727\n",
      "messages: 0.2004702288813261\n",
      "mb_used: 0.32825814117052327\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in zip(features_train.columns, importances):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the most important feature for making predictions is the mb_used column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we aimed to develop a model that could analyze the behavior of Megaline’s subscribers and recommend one of Megaline’s newer plans: Smart or Ultra. The dataset provided contained monthly behavior information about each user, including the number of calls, total call duration in minutes, number of text messages, internet traffic used in MB, and the plan for the current month.\n",
    "\n",
    "The data was already clean with no missing or duplicate values. We split the data into a training set, a validation set, and a test set. We then investigated the quality of different models by changing hyperparameters. We trained a Decision Tree model, a Random Forest model, and a Logistic Regression model, and tuned their hyperparameters to achieve the best performance.\n",
    "\n",
    "The Random Forest model achieved the highest accuracy on the validation set, so we chose it as our final model. We then checked the quality of this model using the test set and achieved an accuracy that met the project’s threshold.\n",
    "\n",
    "We also performed a sanity check on the model by comparing its performance to a random model and a simple model, checking the confusion matrix, and checking the feature importances. The results showed that our model was learning from the data and making sensible predictions.\n",
    "\n",
    "Overall, this project demonstrated the effectiveness of machine learning models in analyzing user behavior and making recommendations. It also highlighted the importance of model selection, hyperparameter tuning, and model evaluation in the machine learning workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
