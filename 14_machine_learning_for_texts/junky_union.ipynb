{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Film Junky Union, a new edgy community for classic movie enthusiasts, is developing a system for filtering and categorizing movie reviews. The goal is to train a model to automatically detect negative reviews. You'll be using a dataset of IMBD movie reviews with polarity labelling to build a model for classifying positive and negative reviews. It will need to have an F1 score of at least 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Overview\n",
    "The core objective of this project is to  evaluate and compare a spectrum of machine learning and deep learning models on their ability to conduct sentiment analysis on a collection of movie and product reviews. By categorizing sentiments into positive, negative, or neutral classes, the project aims to pinpoint the models that most accurately reflect the nuanced sentiments expressed in textual data.\n",
    "\n",
    "Project Objectives\n",
    "- To compare traditional machine learning models (such as Linear SVM, Logistic Regression, and LightGBM) with advanced deep learning techniques (like those using BERT embeddings) in the context of sentiment analysis.\n",
    "- To assess the effectiveness of different feature extraction techniques, including TF-IDF vectorization and BERT embeddings, in capturing the semantic richness of text for sentiment analysis.\n",
    "- To identify the strengths and weaknesses of each model, thereby guiding the selection of the most appropriate sentiment analysis techniques for specific types of textual data and application domains.\n",
    "\n",
    "Methodological Process\n",
    "- Data Preparation: The initial step involves collecting and preprocessing textual data (movie and product reviews) to create a standardized dataset suitable for model training and evaluation.\n",
    "- Feature Extraction: This phase applies TF-IDF vectorization to transform text into numerical features for traditional models and employs BERT embeddings for deep learning models, aiming to capture the semantic essence of the text.\n",
    "- Model Training and Evaluation: Multiple machine learning and deep learning models are trained on the processed data. Their performance is evaluated using metrics such as accuracy, precision, recall, and F1-score to gauge their effectiveness in sentiment analysis.\n",
    "- Comparison and Analysis: The results from different models are compared to analyze their performance in understanding and categorizing sentiments. This comparison sheds light on how various modeling approaches handle the intricacies of human language and emotion.\n",
    "\n",
    "By undertaking this comprehensive approach, the project seeks to advance the understanding of sentiment analysis methodologies and their practical applications, ultimately contributing to more effective and nuanced analysis of human sentiments in textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMClassifier\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_reviews = pd.read_csv('./datasets/imdb_reviews.tsv', sep='\\t', dtype={'votes': 'Int64'})\n",
    "except:\n",
    "    df_reviews = pd.read_csv('https://practicum-content.s3.us-west-1.amazonaws.com/datasets/imdb_reviews.tsv', sep='\\t', dtype={'votes': 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47331 entries, 0 to 47330\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   tconst           47331 non-null  object \n",
      " 1   title_type       47331 non-null  object \n",
      " 2   primary_title    47331 non-null  object \n",
      " 3   original_title   47331 non-null  object \n",
      " 4   start_year       47331 non-null  int64  \n",
      " 5   end_year         47331 non-null  object \n",
      " 6   runtime_minutes  47331 non-null  object \n",
      " 7   is_adult         47331 non-null  int64  \n",
      " 8   genres           47331 non-null  object \n",
      " 9   average_rating   47329 non-null  float64\n",
      " 10  votes            47329 non-null  Int64  \n",
      " 11  review           47331 non-null  object \n",
      " 12  rating           47331 non-null  int64  \n",
      " 13  sp               47331 non-null  object \n",
      " 14  pos              47331 non-null  int64  \n",
      " 15  ds_part          47331 non-null  object \n",
      " 16  idx              47331 non-null  int64  \n",
      "dtypes: Int64(1), float64(1), int64(5), object(10)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tconst",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "primary_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_year",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "runtime_minutes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_adult",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "genres",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "average_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "votes",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pos",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ds_part",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "idx",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c497f2b0-3ea4-4154-be00-d42ecd404e86",
       "rows": [
        [
         "45299",
         "tt0100881",
         "movie",
         "Voices from Beyond",
         "Voci dal profondo",
         "1991",
         "\\N",
         "91",
         "0",
         "Horror,Mystery,Thriller",
         "5.1",
         "946",
         "More of a mystery movie with some gratuitous horror elements thrown in; mediocre overall. It starts with a woman having a nightmare in which her sex partner gets out of bed, goes into the room of her crying child, and kills it. She wakes up. Then, that man is dying in a hospital, spitting up blood. His estranged daughter arrives, and he manages to contact her through her dreams (I think), and he wants her to find out who killed him before his body entirely decomposes in its grave. There's not too much mystery about who did it, or even how; most viewers will have figured that out long before it is revealed. I'm not sure the way he was killed would really have worked. Anyway, the horror elements get in through: a gory autopsy, the recurring dream of the man killing the boy, a nightmare in which a plate of eggs turn into eyes which are then cut, and several shots of the decomposing man both in nightmares and actually in his grave. I was a little surprised to see a dedication in the end by Fulci to Clive Barker! Interesting.",
         "4",
         "neg",
         "0",
         "train",
         "8637"
        ],
        [
         "1839",
         "tt0074113",
         "movie",
         "Alice in Wonderland: An X-Rated Musical Fantasy",
         "Alice in Wonderland: An X-Rated Musical Fantasy",
         "1976",
         "\\N",
         "88",
         "1",
         "Adult,Comedy,Fantasy",
         "6.2",
         "2762",
         "When I was engaged, my fiance and I would frequent the adult bookstores. He would look for his favorite mags, and on occasion a video that caught the eye. As much as I enjoyed the one-on-one with him that the media caused, there was never a video that I really enjoyed. I had seen only one other movie way back when there was a satellite channel called XXX (it dealt with a private eye unraveling a case) that actually had a proper plot and was enjoyable. All the others were grunting and puffing and blowing and whatnot. There's only so many times you can watch a blonde bimbo faking 'it'. This movie caught my eye, and I migrated to it, allowing him to wander the shop. He noticed (how hard was it not too? grins. I was actually interested in something, lol(!) in the video section!) and came over, buying the slightly used copy for me. We took it home and I loved it. Here was a \"Porno\" with a plot. I wasn't sure it even classified as porno, but I use the word loosely. The librarian was a character I could identify with. Alice rejected her boyfriend's advances. She was not comfortable with her own sexuality and prudish in her comments. Bill went away, and she continued to check in books. The White Rabbit ran through the library (one book, if you notice closely, I believe (it's been ten years since I saw the movie) was by Lewis C.) and Alice, for that same reason that propels teenagers to run into the woods when a chainsaw wielding maniac is behind them rather than towards populated areas, follows. It's the best way to get the plot forward. Alice finds herself in Wonderland. I barely recall all the details, but I do remember clearly the swim in the lake, and how she was \"dried\" off. I liked how they got Humpty Dumpty Up again, the Mad Hatter's size of member being on his hat to wear it proudly, and the brother sister team of Dum and Dee (which did disturb me slightly--then again, they could have been husband wife, but I never could tell no matter how many times I watched it). The woman on the knight who told Alice go away and find your own Knight (What's a A Nice Girl Like You Doing on a Knight Like This?). The part that really caught my attention when I watched it about a year or so later was one of the cards (3 of hearts, I think) who resembled my ex's current wife exactly! We couldn't help but tease her about being in the movie! The King of Hearts was interesting, and the Queen was even more so. Due to the openness of the forum, I can't go into details, just say it was \"orgy\" based and we'll leave it at that! When we split up, I was allowed to take the video--he knew I liked it--but in the time since it's been lost in borrowing. Someday I'll find another copy. Btw, if anyone could tell me offlist what scene was cut from the Amazon version, I'd really appreciate it. I heartily recommend this movie for the over 18 crowd. It was soft, sweet, and really 70's, but I liked it immensely. ***** out of 5. D.",
         "10",
         "pos",
         "1",
         "test",
         "3356"
        ],
        [
         "20962",
         "tt0102340",
         "movie",
         "Love Crimes",
         "Love Crimes",
         "1992",
         "\\N",
         "90",
         "0",
         "Romance,Thriller",
         "4.2",
         "845",
         "** CONTAINS SPOILERS ** The truly exquisite Sean Young (who in some scenes, with her hair poofed up, looks something like Elizabeth Taylor) is striking in her opening moments in this film. Sitting in the back of a police car waiting to signal a bust, her face and body are tense and distracted. Unfortunately, once the bust is over Young's strained demeanor never changes. This is one fatally inhibited actress. One has only to compare Young to the performer playing her coworker and best friend, Arnetia Walker, to grasp what is missing in Young. Walker is open, emotional, and at ease at all times...in that there's no apparent barrier between what she may be feeling and her expression of it. She is an open book. Young, on the other hand, acts in the skittish, self-conscious way you might expect your neighbor to act were they suddenly thrown into starring in a film. Basically, she doesn't have a clue. With this major void looming at the center of the movie, we're left to ponder the implausiblities of the story. For instance, after Miss Young is kidnapped by the criminal she's trailing and locked in a closet, she breaks the door down when left alone. Granted, she's dressed only in a bra and panties, but in a similar situation, with a psycho captor due to return any moment, would you head for the door...or take the time to go through his dresser, take out some clothes and get dressed? I would guess that this and other scenes are trying to suggest some sort of mixed emotions Miss Young's character is experiencing, but Young can not convey this type of complexity. There are a few affecting moments in the film, such as the short police interviews with the criminal's past victims, but overall this is an aimless endeavor. It's too bad Miss Young was replaced while filming the pair of comic book style films that might have exploited her limitations with some humor (BATMAN and DICK TRACY), because her floundering while attempting to play actual people is oddly touching. Watching Miss Young try to act, at least in this \"thriller\", is a sad spectacle.",
         "3",
         "neg",
         "0",
         "train",
         "1366"
        ],
        [
         "32705",
         "tt0124102",
         "movie",
         "Strangeland",
         "Strangeland",
         "1998",
         "\\N",
         "85",
         "0",
         "Horror,Thriller",
         "5.2",
         "6451",
         "Wow...This movie really really sucks...'Nuff said. The Story: A psychopathic internet predator stalks and lures young men and women into torturous traps...It goes like this, kidnaps people, they find him, he becomes a changed man and is released on the world yet again, reverts back to his old ways and starts the torture again....The story is stupid, it's implausible. The characters are stupid, they're implausible...Or at the very least way over the top. It's got some very violent imagery, and if you have a week stomach you might just want to stay away...But than again, even if you don't have a week stomach, you might want to stay away...It's that stupid. The Cast: Dee Snider, Kevin Gage...If you're a die hard fan of Twisted Sister and Dee Snider, you might find this one interesting, since he's the writer and star of this film. His acting is laughably bad, and you can tell that he's the one that wrote the God-awful script. Kevin Gage...Well they say he's been in numerous other movies that I've seen, but I don't remember him from any of them...And you won't remember him from this...These two sadly, make the film...They don't make it good mind you...They just make it... One to Five Scale: 1 It's bad...It's very very very bad...In fact it's so bad, that this movie should come with a clip loading pistol to play Russian Rullet with...",
         "1",
         "neg",
         "0",
         "test",
         "1438"
        ],
        [
         "16228",
         "tt0107101",
         "movie",
         "Hellbound",
         "Hellbound",
         "1994",
         "\\N",
         "95",
         "0",
         "Action,Fantasy,Horror",
         "4.9",
         "2949",
         "Norris plays a Chicago cop who stumbles upon a devil's apprentice? who wants to, well, create Armegeddon. He eventually kills the creature by, get this, throwing a solid gold 24 inch spike, not very sharp, about twenty feet, hard enough to penetrate the chest. Unlikely? So is the rest of the movie. Much of it consists of CN and his sidekick driving cars and talking nonsense. The Israeli (or Arab) kid is there ostensibly to humanize CN. OK. Doesn't work, makes no sense, and advances the plot, so-called, not one bit. Also, no cops ever every get invited out of the country to be interviewed by other cops. It is ridiculous as a premise. The whole thing is bad. Unfortunately, it's not so bad as to be entertainingly bad or campy. Just plain bad. But--one can see how Norris was trying to find his way to the successful Walker: Texas Ranger series.",
         "1",
         "neg",
         "0",
         "test",
         "10698"
        ],
        [
         "45482",
         "tt0214382",
         "tvSeries",
         "Walking with Dinosaurs",
         "Walking with Dinosaurs",
         "1999",
         "1999",
         "30",
         "0",
         "Animation,Documentary,History",
         "8.5",
         "5252",
         "When Jurassic Park first came out, it was revolutionary in filmaking and special effects.For the first ever time people cold go to a dinosaur movie and be convinced they were looking at real dinosaurs brought to life.However whilst some dinosaurs were almost perfect examples of what the real creatures could have been like (T.Rex,Brachiosaurus,Triceratops etc)some were altered to fit the movie(Velociraptor,Dilophosaurus)and the film took place n the present on a tropical island where they were not in their natural habitat. Walking With Dinosaurs shows us the real animals in their real habitats all those millions of years ago. The amount of detail and scientific information used in this is great. Now we can view sights such as a grim Triassic desert,a whole herd of Diplodocus, an Icthyosaur give birth, a MASSIVE sea monster, a pterosaurs eye-view,dinosaurs thriving in the South Pole, two Torosaurus lock horns,T.Rex roaring at the camera and the impact of the comet that spelled their doom. These dinosaurs walk,run,feed,fight,breed,hunt and swim. But the series also reveals the other creatures that they shared the world with,two episodes are mainly focused on two different kinds of animals, the flying Pterosaurs and the marine reptiles that lived beneath the waves. The locations and scenery are spectacular and look all the more unique when a CG Dino walks onto screen. And as for the CGI and animatronics, the movements of the CGI dinosaurs look totally and completely natural,the colouring is bright and vivid and the crewmen have taken careful steps to ensure that the CG animals interact with their environments in any way an actual creature would by making splashes in the water,brushing by bushes, kicking up dust and casting shadows on the ground. Admittedly the CG isn't perfect with a few brief instances where the animals look too computery but the rest of the time it looks breathtaking. The puppetry is poor in some cases but it has its moments particularly the scene with the Cynodonts in the first episode. The narration by Kenneth Branagh is pretty good as well giving us vital bits of information and drama at the same time. But of course the true pleasure is seeing a living dinosaur doing what they did all those years ago and also seeing some truly cute moments with Cynodont(mammal/reptile hybrid)pups,Sauropodlets(baby Diplodocus)and T.Rex chicks(Yes even T.Rex can be cute)and then reminds us that nature can be brutal and was even more so back then. All this adds up to a prehistoric nature masterpiece that lets you see a real dinosaur and take your breath away, all from the safety of your living room. If you like nature, Dinosaurs, informative learning, amazing visuals or just to have a truly good viewing and be entertained then Walking With Dinosaurs is definitely for you. Easily recommended.",
         "10",
         "pos",
         "1",
         "test",
         "8326"
        ],
        [
         "25599",
         "tt0443708",
         "movie",
         "Page 3",
         "Page 3",
         "2005",
         "\\N",
         "139",
         "0",
         "Drama",
         "7.3",
         "6599",
         "Madhur has given us a powerful movie Chandni Bar in the past. His next film Page 3 was one of the worst movies of all time. It apparently tells the story of some high class people in India. After seeing a scene where the man forces another man for sexual reasons to Star in a Movie. I felt like spitting and breaking the DVD. Coincidently i did. The reason why was the movie contains scenes of child pornography and molestation. I literally vomited and was shocked to see a movie showing naked children. Very disturbing stuff, there was no need to show the children fully naked. One of the rich guys likes to kidnap poor children and sell them to foreign people, British men in this movie. I am shocked to know this film was a Hit in parts of India, otherwise Super Flop in UK, USA and Australia. I'm from UK, and this kind of stuff makes me sick, shouldn't of been released in UK.",
         "1",
         "neg",
         "0",
         "train",
         "2353"
        ],
        [
         "44488",
         "tt0228979",
         "tvMovie",
         "Two of Us",
         "Two of Us",
         "2000",
         "\\N",
         "89",
         "0",
         "Biography,Drama,Music",
         "7.0",
         "869",
         "I still wonder why I watched this movie. Admittedly, before I viewed this film, I knew practicly nothing about the beatles. I didn't even know all their names! All I knew was that they had a ton of fans, they had some albums that some people claim to be the greatest ever, they broke up, John married Yoko Ono, and John was murdered. Also, VH1 isn't even my favorite music station, MTV is. Still, for some reason or another I decided to watch it, not expecting much. Surprisingly, I enjoyed it very much! The dialogue was written and handled very well with the occasion of a slight accent mess up. This is very important, because John and Paul talking is pretty much the whole film, allthough they are taken outside to explore more possibilities, and to keep you watching. Jared Harris and Adien Quinn give good performaces,overall. The ending was also very smart. I enjoyed how the movie gets you excited about the SNL performace, and then slaps you over the head and makes you realize that it would be better if they just let it go, and end it on a good note. My favorite moment is probably the touching rooftop scene. Overall, I recommend this film to almost everyone. It is a very good way of settling your curiosity of what could have happened if 6 years after the break up Paul just showed up on John's doorstep. Which is probably the main reason of my viewing this film, settling my curiosity on who the beatles really were and what could have happened to them after the breakup.",
         "7",
         "pos",
         "1",
         "train",
         "3467"
        ],
        [
         "36757",
         "tt0033582",
         "movie",
         "The Face Behind the Mask",
         "The Face Behind the Mask",
         "1941",
         "\\N",
         "69",
         "0",
         "Crime,Drama,Film-Noir",
         "7.2",
         "1020",
         "I caught this a few times on TV in the late 1970s. It only played late at night (past midnight). Peter Lorre plays a kind, happy man whose face is disfigured in a fire. He is rejected by his girlfriend and left alone and filled with despair. He turns to a life of crime and eventually becomes very successful. He makes a mask to hide his disfigured features and falls in love with a beautiful girl (Evelyn Keyes)...who is blind! He tries to go straight for her...but he can't escape his life of crime or his hatred of his own scarred face. A no budget B film. Very short (runs only a little over an hour) but well made and superbly acted by Lorre. This has a lot more depth than you would expect from a quickie B picture. Ankers especially takes the thankless \"girl\" role and makes her character fresh and appealing. This has sadly disappeared from TV and was never put on video or DVD (as far as I know). TCM did show it recently and it was great to see the movie still holds up. Highly recommended.",
         "10",
         "pos",
         "1",
         "test",
         "8986"
        ],
        [
         "4961",
         "tt0302346",
         "movie",
         "Blanche",
         "Blanche",
         "2002",
         "\\N",
         "104",
         "0",
         "Adventure,Comedy",
         "3.0",
         "714",
         "I went to see this a few days ago, and it's hard to forget that film...for the wrong reasons. This film is supposed to be funny, it's not, not a single laugh in the theatre( perhaps for josé garcia and gérard Depardieu ), and it's boring, boring, boring. It was even hard sometimes to understand what they were saying. They just talk to fast and don't open their enough for us to understand. I was with a friend and more than 4 or 5 times i caught myself saying after a line that was supposed to be funny \" what, what did he say\", and i'm french. I hate to say that, given the fact that i think good films are made here, but i apologise in advance for all foreigners who will go see the film ( if ever shown outside of France ). We're deeply sorry for that cr@p. 2/10",
         "2",
         "neg",
         "0",
         "train",
         "6959"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>title_type</th>\n",
       "      <th>primary_title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>genres</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sp</th>\n",
       "      <th>pos</th>\n",
       "      <th>ds_part</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45299</th>\n",
       "      <td>tt0100881</td>\n",
       "      <td>movie</td>\n",
       "      <td>Voices from Beyond</td>\n",
       "      <td>Voci dal profondo</td>\n",
       "      <td>1991</td>\n",
       "      <td>\\N</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>Horror,Mystery,Thriller</td>\n",
       "      <td>5.1</td>\n",
       "      <td>946</td>\n",
       "      <td>More of a mystery movie with some gratuitous h...</td>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>8637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>tt0074113</td>\n",
       "      <td>movie</td>\n",
       "      <td>Alice in Wonderland: An X-Rated Musical Fantasy</td>\n",
       "      <td>Alice in Wonderland: An X-Rated Musical Fantasy</td>\n",
       "      <td>1976</td>\n",
       "      <td>\\N</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>Adult,Comedy,Fantasy</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2762</td>\n",
       "      <td>When I was engaged, my fiance and I would freq...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>3356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20962</th>\n",
       "      <td>tt0102340</td>\n",
       "      <td>movie</td>\n",
       "      <td>Love Crimes</td>\n",
       "      <td>Love Crimes</td>\n",
       "      <td>1992</td>\n",
       "      <td>\\N</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>Romance,Thriller</td>\n",
       "      <td>4.2</td>\n",
       "      <td>845</td>\n",
       "      <td>** CONTAINS SPOILERS ** The truly exquisite Se...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32705</th>\n",
       "      <td>tt0124102</td>\n",
       "      <td>movie</td>\n",
       "      <td>Strangeland</td>\n",
       "      <td>Strangeland</td>\n",
       "      <td>1998</td>\n",
       "      <td>\\N</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6451</td>\n",
       "      <td>Wow...This movie really really sucks...'Nuff s...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16228</th>\n",
       "      <td>tt0107101</td>\n",
       "      <td>movie</td>\n",
       "      <td>Hellbound</td>\n",
       "      <td>Hellbound</td>\n",
       "      <td>1994</td>\n",
       "      <td>\\N</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>Action,Fantasy,Horror</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2949</td>\n",
       "      <td>Norris plays a Chicago cop who stumbles upon a...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>10698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45482</th>\n",
       "      <td>tt0214382</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>Walking with Dinosaurs</td>\n",
       "      <td>Walking with Dinosaurs</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>Animation,Documentary,History</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5252</td>\n",
       "      <td>When Jurassic Park first came out, it was revo...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>8326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25599</th>\n",
       "      <td>tt0443708</td>\n",
       "      <td>movie</td>\n",
       "      <td>Page 3</td>\n",
       "      <td>Page 3</td>\n",
       "      <td>2005</td>\n",
       "      <td>\\N</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6599</td>\n",
       "      <td>Madhur has given us a powerful movie Chandni B...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44488</th>\n",
       "      <td>tt0228979</td>\n",
       "      <td>tvMovie</td>\n",
       "      <td>Two of Us</td>\n",
       "      <td>Two of Us</td>\n",
       "      <td>2000</td>\n",
       "      <td>\\N</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>Biography,Drama,Music</td>\n",
       "      <td>7.0</td>\n",
       "      <td>869</td>\n",
       "      <td>I still wonder why I watched this movie. Admit...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>3467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36757</th>\n",
       "      <td>tt0033582</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Face Behind the Mask</td>\n",
       "      <td>The Face Behind the Mask</td>\n",
       "      <td>1941</td>\n",
       "      <td>\\N</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>Crime,Drama,Film-Noir</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1020</td>\n",
       "      <td>I caught this a few times on TV in the late 19...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>8986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>tt0302346</td>\n",
       "      <td>movie</td>\n",
       "      <td>Blanche</td>\n",
       "      <td>Blanche</td>\n",
       "      <td>2002</td>\n",
       "      <td>\\N</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>Adventure,Comedy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>714</td>\n",
       "      <td>I went to see this a few days ago, and it's ha...</td>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>6959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst title_type                                    primary_title  \\\n",
       "45299  tt0100881      movie                               Voices from Beyond   \n",
       "1839   tt0074113      movie  Alice in Wonderland: An X-Rated Musical Fantasy   \n",
       "20962  tt0102340      movie                                      Love Crimes   \n",
       "32705  tt0124102      movie                                      Strangeland   \n",
       "16228  tt0107101      movie                                        Hellbound   \n",
       "45482  tt0214382   tvSeries                           Walking with Dinosaurs   \n",
       "25599  tt0443708      movie                                           Page 3   \n",
       "44488  tt0228979    tvMovie                                        Two of Us   \n",
       "36757  tt0033582      movie                         The Face Behind the Mask   \n",
       "4961   tt0302346      movie                                          Blanche   \n",
       "\n",
       "                                        original_title  start_year end_year  \\\n",
       "45299                                Voci dal profondo        1991       \\N   \n",
       "1839   Alice in Wonderland: An X-Rated Musical Fantasy        1976       \\N   \n",
       "20962                                      Love Crimes        1992       \\N   \n",
       "32705                                      Strangeland        1998       \\N   \n",
       "16228                                        Hellbound        1994       \\N   \n",
       "45482                           Walking with Dinosaurs        1999     1999   \n",
       "25599                                           Page 3        2005       \\N   \n",
       "44488                                        Two of Us        2000       \\N   \n",
       "36757                         The Face Behind the Mask        1941       \\N   \n",
       "4961                                           Blanche        2002       \\N   \n",
       "\n",
       "      runtime_minutes  is_adult                         genres  \\\n",
       "45299              91         0        Horror,Mystery,Thriller   \n",
       "1839               88         1           Adult,Comedy,Fantasy   \n",
       "20962              90         0               Romance,Thriller   \n",
       "32705              85         0                Horror,Thriller   \n",
       "16228              95         0          Action,Fantasy,Horror   \n",
       "45482              30         0  Animation,Documentary,History   \n",
       "25599             139         0                          Drama   \n",
       "44488              89         0          Biography,Drama,Music   \n",
       "36757              69         0          Crime,Drama,Film-Noir   \n",
       "4961              104         0               Adventure,Comedy   \n",
       "\n",
       "       average_rating  votes  \\\n",
       "45299             5.1    946   \n",
       "1839              6.2   2762   \n",
       "20962             4.2    845   \n",
       "32705             5.2   6451   \n",
       "16228             4.9   2949   \n",
       "45482             8.5   5252   \n",
       "25599             7.3   6599   \n",
       "44488             7.0    869   \n",
       "36757             7.2   1020   \n",
       "4961              3.0    714   \n",
       "\n",
       "                                                  review  rating   sp  pos  \\\n",
       "45299  More of a mystery movie with some gratuitous h...       4  neg    0   \n",
       "1839   When I was engaged, my fiance and I would freq...      10  pos    1   \n",
       "20962  ** CONTAINS SPOILERS ** The truly exquisite Se...       3  neg    0   \n",
       "32705  Wow...This movie really really sucks...'Nuff s...       1  neg    0   \n",
       "16228  Norris plays a Chicago cop who stumbles upon a...       1  neg    0   \n",
       "45482  When Jurassic Park first came out, it was revo...      10  pos    1   \n",
       "25599  Madhur has given us a powerful movie Chandni B...       1  neg    0   \n",
       "44488  I still wonder why I watched this movie. Admit...       7  pos    1   \n",
       "36757  I caught this a few times on TV in the late 19...      10  pos    1   \n",
       "4961   I went to see this a few days ago, and it's ha...       2  neg    0   \n",
       "\n",
       "      ds_part    idx  \n",
       "45299   train   8637  \n",
       "1839     test   3356  \n",
       "20962   train   1366  \n",
       "32705    test   1438  \n",
       "16228    test  10698  \n",
       "45482    test   8326  \n",
       "25599   train   2353  \n",
       "44488   train   3467  \n",
       "36757    test   8986  \n",
       "4961    train   6959  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tconst             0\n",
      "title_type         0\n",
      "primary_title      0\n",
      "original_title     0\n",
      "start_year         0\n",
      "end_year           0\n",
      "runtime_minutes    0\n",
      "is_adult           0\n",
      "genres             0\n",
      "average_rating     2\n",
      "votes              2\n",
      "review             0\n",
      "rating             0\n",
      "sp                 0\n",
      "pos                0\n",
      "ds_part            0\n",
      "idx                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column of the DataFrame\n",
    "print(df_reviews.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of sentiment analysis focused on classifying movie reviews as positive or negative, the columns **average_rating** and **votes** are not directly relevant. The primary interest lies in the textual content of the reviews (**review** column) and their associated sentiment labels (**pos** column). The **average_rating** and **votes** columns relate more to the overall audience reception of a film, which, while interesting for other types of analysis (e.g., correlating audience reception with sentiment of reviews), do not contribute to the task of sentiment classification based on the review text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Sentiments:\n",
      "Positive = 1; Negative = 0\n",
      "pos\n",
      "0    23715\n",
      "1    23616\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Distribution of Dataset Partitions (Train/Test):\n",
      "ds_part\n",
      "train    23796\n",
      "test     23535\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Distribution of Title Types:\n",
      "title_type\n",
      "movie           36861\n",
      "tvMovie          2892\n",
      "video            2742\n",
      "tvSeries         2246\n",
      "short             887\n",
      "tvMiniSeries      713\n",
      "tvEpisode         635\n",
      "tvSpecial         183\n",
      "videoGame         154\n",
      "tvShort            18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Distribution of Genres (Top 10):\n",
      "genres\n",
      "Drama                   3392\n",
      "Comedy                  2160\n",
      "Drama,Romance           1808\n",
      "Horror                  1725\n",
      "Comedy,Romance          1304\n",
      "Comedy,Drama,Romance    1212\n",
      "Comedy,Drama            1181\n",
      "Action,Crime,Drama       914\n",
      "Horror,Thriller          890\n",
      "Crime,Drama              648\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Distribution of Adult Classification:\n",
      "is_adult\n",
      "0    47249\n",
      "1       82\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get simple counts for the 'pos' column (sentiment)\n",
    "print(\"Distribution of Sentiments:\")\n",
    "print(\"Positive = 1; Negative = 0\")\n",
    "print(df_reviews['pos'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get simple counts for the 'ds_part' column (dataset partition)\n",
    "print(\"Distribution of Dataset Partitions (Train/Test):\")\n",
    "print(df_reviews['ds_part'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Since 'title_type' and 'genres' can have multiple categories, and 'genres' can be a combination,\n",
    "# it's useful to explore them for insights but keeping in mind the complexity of 'genres'.\n",
    "print(\"Distribution of Title Types:\")\n",
    "print(df_reviews['title_type'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# For 'genres', consider the unique combinations or perhaps the top N if there are many unique combinations.\n",
    "print(\"Distribution of Genres (Top 10):\")\n",
    "print(df_reviews['genres'].value_counts().head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get simple counts for the 'is_adult' column\n",
    "print(\"Distribution of Adult Classification:\")\n",
    "print(df_reviews['is_adult'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at distributions across different dimensions of a dataset is fundamental in understanding its structure, potential biases, and areas that may require special attention during data preprocessing and model training. Here's what we can conclude from the distributions provided:\n",
    "- The dataset is almost perfectly balanced between positive and negative reviews (23715 negative, 23616 positive). This balance is beneficial for training sentiment analysis models, as it reduces the risk of a model being biased towards predicting one sentiment over the other. No special balancing techniques (e.g., oversampling, undersampling) are necessary based on this distribution.\n",
    "- The train and test datasets are also nearly balanced (23796 in train, 23535 in test), indicating that the split was done thoughtfully to ensure both datasets are representative of the overall data.\n",
    "- The majority of reviews are for movies, with significantly fewer reviews for other types like tvMovie, video, and tvSeries. This indicates that any sentiment analysis model trained on this dataset might perform best on movie reviews and potentially less accurately on other media types due to the lower representation in the training data.\n",
    "- The genre distribution shows a variety of genres with Drama being the most common, followed by Comedy and specific combinations like Drama,Romance and Horror. This diversity is good for building a model that can understand sentiments across different genres. However, the model might be more accurate for genres with more data (like Drama and Comedy) and less accurate for less represented genres.\n",
    "- The vast majority of reviews are for non-adult content (47249 non-adult vs. 82 adult). This extreme imbalance suggests that any sentiment analysis model developed might not perform well on adult content due to the lack of training data in this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has no duplicates meaning each entry is unique, which helps in training a model without the concern of overfitting to repeating entries.\n",
    "\n",
    "With the dataset checked for missing values, duplicates, and having gained an understanding of its distribution across various dimensions, we are prepared to move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of movies and reviews over years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "ax = axs[0]\n",
    "\n",
    "dft1 = df_reviews[['tconst', 'start_year']].drop_duplicates() \\\n",
    "    ['start_year'].value_counts().sort_index()\n",
    "dft1 = dft1.reindex(index=np.arange(dft1.index.min(), max(dft1.index.max(), 2021))).fillna(0)\n",
    "dft1.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of Movies Over Years')\n",
    "\n",
    "ax = axs[1]\n",
    "\n",
    "dft2 = df_reviews.groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "\n",
    "dft2.plot(kind='bar', stacked=True, label='#reviews (neg, pos)', ax=ax)\n",
    "\n",
    "dft2 = df_reviews['start_year'].value_counts().sort_index()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "dft3 = (dft2/dft1).fillna(0)\n",
    "axt = ax.twinx()\n",
    "dft3.reset_index(drop=True).rolling(5).mean().plot(color='orange', label='reviews per movie (avg over 5 years)', ax=axt)\n",
    "\n",
    "lines, labels = axt.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='upper left')\n",
    "\n",
    "ax.set_title('Number of Reviews Over Years')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall trend in the number of movies over the last 10 years ending in 2010: 225.4\n",
      "Year with the maximum number of movies in the last 10 years ending in 2010: 2006\n",
      "Overall trend in the number of reviews over the last 10 years ending in 2010: 1842.7\n",
      "Year with the maximum number of reviews in the last 10 years ending in 2010: 2006\n",
      "Average number of reviews per movie over the last 5 years ending in 2010: 9.340290693016419\n"
     ]
    }
   ],
   "source": [
    "# Adjust the range to the last 10 years ending in 2010\n",
    "last_10_years = np.arange(2001, 2011)\n",
    "\n",
    "# 1. Overall trend in the number of movies over the last 10 years ending in 2010\n",
    "movies_last_10_years = dft1.loc[last_10_years]\n",
    "movie_count_trend_last_10_years = movies_last_10_years.mean()\n",
    "\n",
    "# 2. Year with the maximum number of movies in the last 10 years ending in 2010\n",
    "year_max_movies_last_10_years = movies_last_10_years.idxmax()\n",
    "\n",
    "# 3. Overall trend in the number of reviews over the last 10 years ending in 2010\n",
    "reviews_last_10_years = dft2.loc[last_10_years]\n",
    "review_count_trend_last_10_years = reviews_last_10_years.mean()\n",
    "\n",
    "# 4. Year with the maximum number of reviews in the last 10 years ending in 2010\n",
    "year_max_reviews_last_10_years = reviews_last_10_years.idxmax()\n",
    "\n",
    "# 5. Average number of reviews per movie over the last 5 years ending in 2010\n",
    "# Adjust the range to the last 5 years ending in 2010\n",
    "last_5_years = np.arange(2006, 2011)\n",
    "reviews_per_movie_last_5_years = dft3.loc[last_5_years]\n",
    "avg_reviews_per_movie_last_5_years = reviews_per_movie_last_5_years.mean()\n",
    "\n",
    "# Printing the key data points\n",
    "print(f\"Overall trend in the number of movies over the last 10 years ending in 2010: {movie_count_trend_last_10_years}\")\n",
    "print(f\"Year with the maximum number of movies in the last 10 years ending in 2010: {year_max_movies_last_10_years}\")\n",
    "print(f\"Overall trend in the number of reviews over the last 10 years ending in 2010: {review_count_trend_last_10_years}\")\n",
    "print(f\"Year with the maximum number of reviews in the last 10 years ending in 2010: {year_max_reviews_last_10_years}\")\n",
    "print(f\"Average number of reviews per movie over the last 5 years ending in 2010: {avg_reviews_per_movie_last_5_years}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, there were 225.4 movies per year over the last 10 years ending in 2010. The year 2006 had the highest number of movies compared to other years in that decade. Similar to the number of movies, 2006 also had the highest number of reviews. There was an average of 1842.7 reviews per year in the last decade leading up to 2010.  In the last 5 years ending in 2010, there was an average of approximately 9.34 reviews per movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of number of reviews per movie with the exact counting and KDE (just to learn how it may differ from the exact counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.groupby('tconst')['review'].count() \\\n",
    "    .value_counts() \\\n",
    "    .sort_index()\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_title('Bar Plot of #Reviews Per Movie')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.groupby('tconst')['review'].count()\n",
    "sns.kdeplot(dft, ax=ax)\n",
    "ax.set_title('KDE Plot of #Reviews Per Movie')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both plots indicate the data is right-skewed, meaning there are a few movies with many reviews and many movies with few reviews. They also peak at 1 review. The majority of movies have only a handful of reviews, which might represent the general trend for most films, while a few movies (blockbusters or critically acclaimed films) receive a substantial amount of attention. The spike in the bar graph for movies with 30 or more reviews could be indicative of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "pos",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "47a104ca-eeb7-4433-bbbb-7ee9347d6c94",
       "rows": [
        [
         "0",
         "23715"
        ],
        [
         "1",
         "23616"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "pos\n",
       "0    23715\n",
       "1    23616\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.query('ds_part == \"train\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('The train set: distribution of ratings')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.query('ds_part == \"test\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('The test set: distribution of ratings')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The histograms show the frequency of each rating value in both the train and test datasets. Both the train and test sets show a similar pattern of distribution. The distribution pattern between the train and test sets is quite consistent, suggesting that the split between training and testing data has been done properly, maintaining a similar distribution of ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of negative and positive reviews over the years for two parts of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cosmi\\AppData\\Local\\Temp\\ipykernel_34052\\2564148758.py:14: UserWarning: \n",
      "\n",
      "Support for alternate kernels has been removed; using Gaussian kernel.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
      "C:\\Users\\cosmi\\AppData\\Local\\Temp\\ipykernel_34052\\2564148758.py:15: UserWarning: \n",
      "\n",
      "Support for alternate kernels has been removed; using Gaussian kernel.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
      "C:\\Users\\cosmi\\AppData\\Local\\Temp\\ipykernel_34052\\2564148758.py:30: UserWarning: \n",
      "\n",
      "Support for alternate kernels has been removed; using Gaussian kernel.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
      "C:\\Users\\cosmi\\AppData\\Local\\Temp\\ipykernel_34052\\2564148758.py:31: UserWarning: \n",
      "\n",
      "Support for alternate kernels has been removed; using Gaussian kernel.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(16, 8), gridspec_kw=dict(width_ratios=(2, 1), height_ratios=(1, 1)))\n",
    "\n",
    "ax = axs[0][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('The train set: number of reviews of different polarities per year')\n",
    "\n",
    "ax = axs[0][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('The train set: distribution of different polarities per movie')\n",
    "\n",
    "ax = axs[1][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('The test set: number of reviews of different polarities per year')\n",
    "\n",
    "ax = axs[1][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('The test set: distribution of different polarities per movie')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composing an evaluation routine which can be used for all models in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def evaluate_model(model, train_features, train_target, test_features, test_target):\n",
    "    \n",
    "    eval_stats = {}\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 6)) \n",
    "    \n",
    "    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):\n",
    "        \n",
    "        eval_stats[type] = {}\n",
    "    \n",
    "        pred_target = model.predict(features)\n",
    "        pred_proba = model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        # F1\n",
    "        f1_thresholds = np.arange(0, 1.01, 0.05)\n",
    "        f1_scores = [metrics.f1_score(target, pred_proba>=threshold) for threshold in f1_thresholds]\n",
    "        \n",
    "        # ROC\n",
    "        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)\n",
    "        roc_auc = metrics.roc_auc_score(target, pred_proba)    \n",
    "        eval_stats[type]['ROC AUC'] = roc_auc\n",
    "\n",
    "        # PRC\n",
    "        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)\n",
    "        aps = metrics.average_precision_score(target, pred_proba)\n",
    "        eval_stats[type]['APS'] = aps\n",
    "        \n",
    "        if type == 'train':\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'green'\n",
    "\n",
    "        # F1 Score\n",
    "        ax = axs[0]\n",
    "        max_f1_score_idx = np.argmax(f1_scores)\n",
    "        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')\n",
    "        # setting crosses for some thresholds\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('threshold')\n",
    "        ax.set_ylabel('F1')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'F1 Score') \n",
    "\n",
    "        # ROC\n",
    "        ax = axs[1]    \n",
    "        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')\n",
    "        # setting crosses for some thresholds\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'            \n",
    "            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.legend(loc='lower center')        \n",
    "        ax.set_title(f'ROC Curve')\n",
    "        \n",
    "        # PRC\n",
    "        ax = axs[2]\n",
    "        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')\n",
    "        # setting crosses for some thresholds\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('recall')\n",
    "        ax.set_ylabel('precision')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'PRC')        \n",
    "\n",
    "        eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)\n",
    "        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)\n",
    "    \n",
    "    df_eval_stats = pd.DataFrame(eval_stats)\n",
    "    df_eval_stats = df_eval_stats.round(2)\n",
    "    df_eval_stats = df_eval_stats.reindex(index=('Accuracy', 'F1', 'APS', 'ROC AUC'))\n",
    "    \n",
    "    print(df_eval_stats)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume all models below accepts texts in lowercase and without any digits, punctuations marks etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to normalize the text\n",
    "def normalize_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the normalization function to each review in the dataframe\n",
    "df_reviews['review_norm'] = df_reviews['review'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, the whole dataset is already divided into train/test one parts. The corresponding flag is 'ds_part'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23796, 18)\n",
      "(23535, 18)\n"
     ]
    }
   ],
   "source": [
    "df_reviews_train = df_reviews.query('ds_part == \"train\"').copy()\n",
    "df_reviews_test = df_reviews.query('ds_part == \"test\"').copy()\n",
    "\n",
    "train_target = df_reviews_train['pos']\n",
    "test_target = df_reviews_test['pos']\n",
    "\n",
    "print(df_reviews_train.shape)\n",
    "print(df_reviews_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0 - Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DummyClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.dummy.DummyClassifier.html\">?<span>Documentation for DummyClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DummyClassifier object with a strategy to always predict the most frequent class\n",
    "dummy_model = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit the dummy model on the training data\n",
    "dummy_model.fit(df_reviews_train['review_norm'], train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train  test\n",
      "Accuracy    0.5   0.5\n",
      "F1          0.0   0.0\n",
      "APS         0.5   0.5\n",
      "ROC AUC     0.5   0.5\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(dummy_model, \n",
    "               df_reviews_train['review_norm'], train_target, \n",
    "               df_reviews_test['review_norm'], test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - NLTK, TF-IDF and LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cosmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the set of stopwords from NLTK\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load English stopwords and convert the set to a list\n",
    "english_stopwords = list(stopwords.words('english'))\n",
    "\n",
    "# Initialize a TfidfVectorizer with stopwords and fit it on the training data\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=english_stopwords)\n",
    "\n",
    "# Fit and transform the training data to create TF-IDF features\n",
    "train_features_1 = tfidf_vectorizer.fit_transform(df_reviews_train['review_norm'])\n",
    "\n",
    "# Transform the test data to create TF-IDF features\n",
    "test_features_1 = tfidf_vectorizer.transform(df_reviews_test['review_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a Logistic Regression model\n",
    "model_1 = LogisticRegression(random_state=0)\n",
    "\n",
    "# Train the model with the training data and the corresponding labels\n",
    "model_1.fit(train_features_1, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train  test\n",
      "Accuracy   0.94  0.88\n",
      "F1         0.94  0.88\n",
      "APS        0.98  0.95\n",
      "ROC AUC    0.98  0.95\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_1, train_features_1, train_target, test_features_1, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - spaCy, TF-IDF and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_3(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    #tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the text preprocessing function to the 'review_norm' column of the training and test data\n",
    "df_reviews_train['review_lemma'] = df_reviews_train['review_norm'].apply(text_preprocessing_3)\n",
    "df_reviews_test['review_lemma'] = df_reviews_test['review_norm'].apply(text_preprocessing_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TfidfVectorizer without passing the stop words since we've already done preprocessing\n",
    "tfidf_vectorizer_3 = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data to create TF-IDF features\n",
    "train_features_3 = tfidf_vectorizer_3.fit_transform(df_reviews_train['review_lemma'])\n",
    "\n",
    "# Transform the test data to create TF-IDF features\n",
    "test_features_3 = tfidf_vectorizer_3.transform(df_reviews_test['review_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "model_3 = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_3.fit(train_features_3, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train  test\n",
      "Accuracy   0.93  0.88\n",
      "F1         0.93  0.88\n",
      "APS        0.98  0.95\n",
      "ROC AUC    0.98  0.95\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluate_model(model_3, train_features_3, train_target, test_features_3, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - spaCy, TF-IDF and LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11884, number of negative: 11912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.338875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 471910\n",
      "[LightGBM] [Info] Number of data points in the train set: 23796, number of used features: 9456\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499412 -> initscore=-0.002353\n",
      "[LightGBM] [Info] Start training from score -0.002353\n",
      "          train  test\n",
      "Accuracy   0.92  0.86\n",
      "F1         0.92  0.86\n",
      "APS        0.98  0.93\n",
      "ROC AUC    0.98  0.94\n"
     ]
    }
   ],
   "source": [
    "# Create and train an LGBMClassifier model\n",
    "lgbm_model = LGBMClassifier(random_state=12345, n_jobs=-1)\n",
    "lgbm_model.fit(train_features_3, train_target)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(lgbm_model, train_features_3, train_target, test_features_3, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model 9 - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and model configuration\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_text_to_embeddings(texts, max_length=512, batch_size=100, force_device=None, disable_progress_bar=False):\n",
    "    # Convert texts to tokens, pad to max_length, and create attention masks\n",
    "    ids_list = []\n",
    "    attention_mask_list = []\n",
    "    for text in texts:\n",
    "        # Tokenize text and add special tokens ([CLS], [SEP])\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text,                      # Input text\n",
    "            add_special_tokens=True,   # Add '[CLS]' and '[SEP]'\n",
    "            max_length=max_length,     # Pad & truncate all sentences\n",
    "            padding='max_length',    # Pad all to max_length\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,# Construct attention masks\n",
    "            return_tensors='pt',       # Return PyTorch tensors\n",
    "        )\n",
    "        ids_list.append(encoded_dict['input_ids'])\n",
    "        attention_mask_list.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # Flatten the list of tensors to a single tensor\n",
    "    ids_list = torch.cat(ids_list, dim=0)\n",
    "    attention_mask_list = torch.cat(attention_mask_list, dim=0)\n",
    "    \n",
    "    # Set device based on availability and preference\n",
    "    if force_device is not None:\n",
    "        device = torch.device(force_device)\n",
    "    else:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    model.to(device)\n",
    "    if not disable_progress_bar:\n",
    "        print(f'Using the {device} device.')\n",
    "    \n",
    "    # Process embeddings in batches\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(math.ceil(len(ids_list)/batch_size)), disable=disable_progress_bar):\n",
    "        ids_batch = ids_list[batch_size*i:batch_size*(i+1)].to(device)\n",
    "        attention_mask_batch = attention_mask_list[batch_size*i:batch_size*(i+1)].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            batch_embeddings = model(input_ids=ids_batch, attention_mask=attention_mask_batch)\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].detach().cpu().numpy())\n",
    "        \n",
    "    return np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the cuda device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [05:38<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the cuda device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [05:26<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Attention! Running BERT for thousands of texts may take long run on CPU, at least several hours\n",
    "train_features_9 = BERT_text_to_embeddings(df_reviews_train['review_norm'], force_device='cuda')\n",
    "test_features_9 = BERT_text_to_embeddings(df_reviews_test['review_norm'], force_device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87     11803\n",
      "           1       0.87      0.85      0.86     11732\n",
      "\n",
      "    accuracy                           0.86     23535\n",
      "   macro avg       0.86      0.86      0.86     23535\n",
      "weighted avg       0.86      0.86      0.86     23535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training a Logistic Regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "logreg_model.fit(train_features_9, train_target)\n",
    "\n",
    "test_predictions = logreg_model.predict(test_features_9)\n",
    "print(classification_report(test_target, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings\n",
    "np.savez_compressed('features_9.npz', train_features_9=train_features_9, test_features_9=test_features_9)\n",
    "\n",
    "# Load the embeddings\n",
    "with np.load('features_9.npz') as data:\n",
    "    train_features_9 = data['train_features_9']\n",
    "    test_features_9 = data['test_features_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23796,)\n",
      "(23796, 768)\n",
      "(23796,)\n"
     ]
    }
   ],
   "source": [
    "print(df_reviews_train['review_norm'].shape)\n",
    "print(train_features_9.shape)\n",
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results\n",
    "- The model exhibits strong and balanced performance across both classes, with high precision, recall, and F1-scores. This suggests it is equally good at identifying both positive and negative sentiments without significant bias toward either class.\n",
    "\n",
    "- The balanced scores and high accuracy indicate that the BERT embeddings provide a robust feature set for sentiment analysis, enabling the Logistic Regression model to effectively capture and classify the sentiment expressed in the reviews.\n",
    "\n",
    "- Given the complexity and variability of natural language, an accuracy of 0.86 is commendable, especially for a relatively simple model like Logistic Regression paired with powerful embeddings from BERT.\n",
    "\n",
    "- The nearly equal number of instances in each class (support) helps ensure that the model's performance metrics are not skewed by class imbalance, making the high scores even more meaningful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_norm",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6351716f-6576-4eee-b4d9-ab031839a824",
       "rows": [
        [
         "0",
         "I did not simply like it, not my kind of movie.",
         "i did not simply like it not my kind of movie"
        ],
        [
         "1",
         "Well, I was bored and felt asleep in the middle of the movie.",
         "well i was bored and felt asleep in the middle of the movie"
        ],
        [
         "2",
         "I was really fascinated with the movie",
         "i was really fascinated with the movie"
        ],
        [
         "3",
         "Even the actors looked really old and disinterested, and they got paid to be in the movie. What a soulless cash grab.",
         "even the actors looked really old and disinterested and they got paid to be in the movie what a soulless cash grab"
        ],
        [
         "4",
         "I didn't expect the reboot to be so good! Writers really cared about the source material",
         "i didnt expect the reboot to be so good writers really cared about the source material"
        ],
        [
         "5",
         "The movie had its upsides and downsides, but I feel like overall it's a decent flick. I could see myself going to see it again.",
         "the movie had its upsides and downsides but i feel like overall its a decent flick i could see myself going to see it again"
        ],
        [
         "6",
         "What a rotten attempt at a comedy. Not a single joke lands, everyone acts annoying and loud, even kids won't like this!",
         "what a rotten attempt at a comedy not a single joke lands everyone acts annoying and loud even kids wont like this"
        ],
        [
         "7",
         "Launching on Netflix was a brave move & I really appreciate being able to binge on episode after episode, of this exciting intelligent new drama.",
         "launching on netflix was a brave move  i really appreciate being able to binge on episode after episode of this exciting intelligent new drama"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I did not simply like it, not my kind of movie.</td>\n",
       "      <td>i did not simply like it not my kind of movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, I was bored and felt asleep in the middl...</td>\n",
       "      <td>well i was bored and felt asleep in the middle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was really fascinated with the movie</td>\n",
       "      <td>i was really fascinated with the movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even the actors looked really old and disinter...</td>\n",
       "      <td>even the actors looked really old and disinter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I didn't expect the reboot to be so good! Writ...</td>\n",
       "      <td>i didnt expect the reboot to be so good writer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The movie had its upsides and downsides, but I...</td>\n",
       "      <td>the movie had its upsides and downsides but i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What a rotten attempt at a comedy. Not a singl...</td>\n",
       "      <td>what a rotten attempt at a comedy not a single...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Launching on Netflix was a brave move &amp; I real...</td>\n",
       "      <td>launching on netflix was a brave move  i reall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0    I did not simply like it, not my kind of movie.   \n",
       "1  Well, I was bored and felt asleep in the middl...   \n",
       "2             I was really fascinated with the movie   \n",
       "3  Even the actors looked really old and disinter...   \n",
       "4  I didn't expect the reboot to be so good! Writ...   \n",
       "5  The movie had its upsides and downsides, but I...   \n",
       "6  What a rotten attempt at a comedy. Not a singl...   \n",
       "7  Launching on Netflix was a brave move & I real...   \n",
       "\n",
       "                                         review_norm  \n",
       "0      i did not simply like it not my kind of movie  \n",
       "1  well i was bored and felt asleep in the middle...  \n",
       "2             i was really fascinated with the movie  \n",
       "3  even the actors looked really old and disinter...  \n",
       "4  i didnt expect the reboot to be so good writer...  \n",
       "5  the movie had its upsides and downsides but i ...  \n",
       "6  what a rotten attempt at a comedy not a single...  \n",
       "7  launching on netflix was a brave move  i reall...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feel free to completely remove these reviews and try your models on your own reviews, those below are just examples\n",
    "\n",
    "my_reviews = pd.DataFrame([\n",
    "    'I did not simply like it, not my kind of movie.',\n",
    "    'Well, I was bored and felt asleep in the middle of the movie.',\n",
    "    'I was really fascinated with the movie',    \n",
    "    'Even the actors looked really old and disinterested, and they got paid to be in the movie. What a soulless cash grab.',\n",
    "    'I didn\\'t expect the reboot to be so good! Writers really cared about the source material',\n",
    "    'The movie had its upsides and downsides, but I feel like overall it\\'s a decent flick. I could see myself going to see it again.',\n",
    "    'What a rotten attempt at a comedy. Not a single joke lands, everyone acts annoying and loud, even kids won\\'t like this!',\n",
    "    'Launching on Netflix was a brave move & I really appreciate being able to binge on episode after episode, of this exciting intelligent new drama.'\n",
    "], columns=['review'])\n",
    "\n",
    "my_reviews['review_norm'] = my_reviews['review'].apply(normalize_text)\n",
    "\n",
    "my_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16:  i did not simply like it not my kind of movie\n",
      "0.17:  well i was bored and felt asleep in the middle of the movie\n",
      "0.57:  i was really fascinated with the movie\n",
      "0.13:  even the actors looked really old and disinterested and they got paid to be in the movie what a soul\n",
      "0.26:  i didnt expect the reboot to be so good writers really cared about the source material\n",
      "0.48:  the movie had its upsides and downsides but i feel like overall its a decent flick i could see mysel\n",
      "0.05:  what a rotten attempt at a comedy not a single joke lands everyone acts annoying and loud even kids \n",
      "0.84:  launching on netflix was a brave move  i really appreciate being able to binge on episode after epis\n"
     ]
    }
   ],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "texts_transformed = tfidf_vectorizer.transform(texts)\n",
    "my_reviews_pred_prob = model_1.predict_proba(texts_transformed)[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15:  i did not simply like it not my kind of movie\n",
      "0.21:  well i was bored and felt asleep in the middle of the movie\n",
      "0.50:  i was really fascinated with the movie\n",
      "0.16:  even the actors looked really old and disinterested and they got paid to be in the movie what a soul\n",
      "0.19:  i didnt expect the reboot to be so good writers really cared about the source material\n",
      "0.70:  the movie had its upsides and downsides but i feel like overall its a decent flick i could see mysel\n",
      "0.04:  what a rotten attempt at a comedy not a single joke lands everyone acts annoying and loud even kids \n",
      "0.87:  launching on netflix was a brave move  i really appreciate being able to binge on episode after epis\n"
     ]
    }
   ],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "\n",
    "my_reviews_pred_prob = model_3.predict_proba(tfidf_vectorizer_3.transform(texts.apply(lambda x: text_preprocessing_3(x))))[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50:  i did not simply like it not my kind of movie\n",
      "0.54:  well i was bored and felt asleep in the middle of the movie\n",
      "0.62:  i was really fascinated with the movie\n",
      "0.56:  even the actors looked really old and disinterested and they got paid to be in the movie what a soul\n",
      "0.40:  i didnt expect the reboot to be so good writers really cared about the source material\n",
      "0.74:  the movie had its upsides and downsides but i feel like overall its a decent flick i could see mysel\n",
      "0.19:  what a rotten attempt at a comedy not a single joke lands everyone acts annoying and loud even kids \n",
      "0.72:  launching on netflix was a brave move  i really appreciate being able to binge on episode after epis\n"
     ]
    }
   ],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "\n",
    "tfidf_vectorizer_4 = tfidf_vectorizer_3\n",
    "my_reviews_pred_prob = lgbm_model.predict_proba(tfidf_vectorizer_4.transform(texts.apply(lambda x: text_preprocessing_3(x))))[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38:  i did not simply like it not my kind of movie\n",
      "0.01:  well i was bored and felt asleep in the middle of the movie\n",
      "0.99:  i was really fascinated with the movie\n",
      "0.01:  even the actors looked really old and disinterested and they got paid to be in the movie what a soul\n",
      "0.08:  i didnt expect the reboot to be so good writers really cared about the source material\n",
      "0.99:  the movie had its upsides and downsides but i feel like overall its a decent flick i could see mysel\n",
      "0.02:  what a rotten attempt at a comedy not a single joke lands everyone acts annoying and loud even kids \n",
      "0.98:  launching on netflix was a brave move  i really appreciate being able to binge on episode after epis\n"
     ]
    }
   ],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "\n",
    "my_reviews_features_9 = BERT_text_to_embeddings(texts, disable_progress_bar=True)\n",
    "\n",
    "my_reviews_pred_prob = logreg_model.predict_proba(my_reviews_features_9)[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the models on the provided reviews reveals distinct differences in how they assess sentiment, indicating variations in sensitivity, specificity, and possibly the underlying features they prioritize during prediction. Here's a brief analysis of each model's performance based on the predicted probabilities for the sentiment of each review:\n",
    "\n",
    "Model 2: Linear SVM with TF-IDF\n",
    "- Sensitivity: This model seems conservative in its predictions, mostly leaning towards neutral to negative sentiment (lower probabilities) across a range of reviews. It only shows high confidence in positive sentiment for the review about Netflix, indicating a possible preference for explicit positive indicators.\n",
    "- Specificity: It is good at identifying clearly negative sentiments with low scores but struggles with nuanced positive expressions, as seen in the moderate scores for some positive reviews.\n",
    "\n",
    "Model 3: Logistic Regression with TF-IDF\n",
    "- Sensitivity: Similar to Model 2, this model is conservative but shows slightly higher probabilities on average for positive reviews. It's more confident in its assessment of the Netflix review and a decent flick, indicating it might be better at picking up nuanced positivity than Model 2.\n",
    "- Specificity: It effectively identifies strongly negative sentiments but, like Model 2, may misinterpret nuanced or mixed sentiments.\n",
    "\n",
    "Model 4: LightGBM with TF-IDF\n",
    "- Sensitivity: This model has a broader range of predictions, indicating a different sensitivity to features within the text. It's more optimistic, assigning higher probabilities to positive sentiments but also showing higher probabilities for some negative reviews.\n",
    "- Specificity: Its specificity seems compromised as it assigns moderate to high probabilities across the board, which could indicate a challenge in distinguishing between nuanced negative and positive sentiments.\n",
    "\n",
    "Model 9: Logistic Regression with BERT Embeddings\n",
    "- Sensitivity: This model shows a stark contrast in its predictions, with high probabilities for positive sentiments and very low for negative, indicating a strong differentiation between positive and negative sentiments based on BERT embeddings.\n",
    "- Specificity: It excels in identifying both strongly positive and strongly negative sentiments, as indicated by the high contrast in its predictions. This suggests a high specificity, especially in recognizing clear sentiment expressions.\n",
    "\n",
    "Performance Summary\n",
    "- Handling Nuanced Sentiments: Model 9 (BERT Embeddings) stands out for its ability to differentiate between positive and negative sentiments clearly, likely due to the rich contextual information captured by BERT embeddings. Models 2 and 3 are more conservative, possibly due to limitations in capturing nuanced sentiments with TF-IDF features. Model 4 shows a varied approach but may struggle with specificity.\n",
    "- Sensitivity and Specificity: Model 9 demonstrates high sensitivity and specificity, particularly in distinguishing positive sentiments. Models 2 and 3 are more conservative, possibly erring on the side of caution and thus potentially missing nuanced sentiments. Model 4’s broader prediction range suggests a different interpretation of features but may need refinement to improve specificity.\n",
    "- Overall Effectiveness: Based on the provided predictions, Model 9 appears to be the most effective in capturing a wide range of sentiments, from strongly negative to strongly positive, indicating the power of BERT embeddings in sentiment analysis tasks. The other models, while having their strengths, show varying degrees of effectiveness, with potential areas for improvement in handling nuanced or mixed sentiments.\n",
    "\n",
    "These observations suggest that the choice of model and features (TF-IDF vs. BERT embeddings) significantly impacts sentiment analysis performance, especially in handling nuanced expressions of sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer-Based Sentiment Classification (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_reviews[df_reviews[\"ds_part\"] == \"train\"]\n",
    "test_df = df_reviews[df_reviews[\"ds_part\"] == \"test\"]\n",
    "\n",
    "train_texts = train_df[\"review\"].tolist()\n",
    "train_labels = train_df[\"pos\"].tolist()\n",
    "\n",
    "test_texts = test_df[\"review\"].tolist()\n",
    "test_labels = test_df[\"pos\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize training and test texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tconst', 'title_type', 'primary_title', 'original_title', 'start_year', 'end_year', 'runtime_minutes', 'is_adult', 'genres', 'average_rating', 'votes', 'review', 'rating', 'sp', 'labels', 'ds_part', 'idx', 'review_norm', 'review_lemma', '__index_level_0__'],\n",
      "    num_rows: 23796\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create train and test dataframes from the original\n",
    "# train_df = df_reviews[df_reviews['ds_part'] == 'train'][['review', 'pos']]\n",
    "# test_df = df_reviews[df_reviews['ds_part'] == 'test'][['review', 'pos']]\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_reviews_train)\n",
    "test_dataset = Dataset.from_pandas(df_reviews_test)\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"pos\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"pos\", \"labels\")\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a04d0d896c44dbb8f49a9f891af2911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f53fa28d7244ae94c2f23f0fe92f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels),\n",
    "        \"f1\": f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cosmi\\AppData\\Local\\Temp\\ipykernel_34052\\2154125205.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4464' max='4464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4464/4464 36:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.229377</td>\n",
       "      <td>{'accuracy': 0.9089441257701296}</td>\n",
       "      <td>{'f1': 0.9086519985542066}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>{'accuracy': 0.9287444231994901}</td>\n",
       "      <td>{'f1': 0.9287374501763692}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.293957</td>\n",
       "      <td>{'accuracy': 0.9308264287231782}</td>\n",
       "      <td>{'f1': 0.930826267620901}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='368' max='368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [368/368 02:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22937694191932678,\n",
       " 'eval_accuracy': {'accuracy': 0.9089441257701296},\n",
       " 'eval_f1': {'f1': 0.9086519985542066},\n",
       " 'eval_runtime': 178.8246,\n",
       " 'eval_samples_per_second': 131.609,\n",
       " 'eval_steps_per_second': 2.058,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Findings:\n",
    "- Model Performance Variability: There was a noticeable variance in the performance of models, influenced by the type of feature extraction (TF-IDF vs. BERT embeddings) and the algorithm used. This variance underscores the importance of choosing the right combination of feature representation and machine learning technique based on the specific requirements of the sentiment analysis task.\n",
    "\n",
    "- Effectiveness of BERT Embeddings: The model utilizing BERT embeddings demonstrated superior performance in distinguishing between sentiments with greater accuracy. This model showed a remarkable ability to capture nuanced expressions of sentiment, likely due to BERT's deep contextual understanding of language, which surpasses the capabilities of traditional vectorization methods like TF-IDF.\n",
    "\n",
    "- Challenges with Traditional Models: Traditional models using TF-IDF vectorization showed a more conservative approach to sentiment prediction, often leaning towards neutral or less definitive sentiment classifications. While effective in certain contexts, these models may struggle with the complexity and subtlety of human language, especially when dealing with nuanced or mixed sentiments.\n",
    "\n",
    "The exploration of different models for sentiment analysis has highlighted the critical role of feature representation and model choice in effectively interpreting sentiments in text. The superior performance of the BERT-based model underscores the advancements in NLP technology, offering deeper insights into sentiment analysis tasks. However, the variability in model performance also suggests that there is no one-size-fits-all solution; the choice of model should be tailored to the specific nuances of the dataset and the objectives of the sentiment analysis. Moving forward, leveraging advanced NLP techniques and exploring innovative modeling approaches will be key to enhancing the accuracy and applicability of sentiment analysis in various domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
